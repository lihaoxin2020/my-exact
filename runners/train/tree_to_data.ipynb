{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert RMCTS results to SFT trainable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DATASET'] = 'visualwebarena'\n",
    "os.environ['CLASSIFIEDS'] = 'http://xxx:57981'\n",
    "os.environ['CLASSIFIEDS_RESET_TOKEN'] = \"4b61655535e7ed388f0d40a93600254c\"\n",
    "os.environ['SHOPPING'] = \"http://xxx:55777\"\n",
    "os.environ['REDDIT'] = \"http://xxx:55999\"\n",
    "os.environ['WIKIPEDIA'] = \"http://xxx:55888\"\n",
    "os.environ['SHOPPING_ADMIN'] = \"http://xxx:55988/admin\"\n",
    "os.environ['GITLAB'] = \"http://xxx:58023\"\n",
    "os.environ['MAP'] = \"http://xxx:3000\"\n",
    "os.environ['HOMEPAGE'] = \"http://xxx:55399\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PROVIDER'] = 'openai'\n",
    "os.environ['AGENT_LLM_API_BASE'] = \"https://xxx\"\n",
    "os.environ['AGENT_LLM_API_KEY'] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = \"org-xxx\"\n",
    "os.environ[\"OPENAI_ORG_ID\"] = \"org-xxx\"\n",
    "os.environ['VALUE_FUNC_PROVIDER'] = 'openai'\n",
    "os.environ['VALUE_FUNC_API_BASE'] = \"https://xxx\"\n",
    "os.environ['RLM_PROVIDER'] = 'openai'\n",
    "os.environ['EMBEDDING_MODEL_PROVIDER'] = 'openai'\n",
    "os.environ['AZURE_TOKEN_PROVIDER_BASE'] = 'https://xxx'\n",
    "os.environ['AZURE_OPENAI_API_VERSION'] = \"\"\n",
    "\n",
    "\n",
    "from src.llms.lm_config import LMConfig\n",
    "from src.llms.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "llm_config = LMConfig(\n",
    "    provider=os.environ['PROVIDER'],\n",
    "    model=\"gpt-4o\",\n",
    "    mode=\"chat\"\n",
    ")\n",
    "llm_config.gen_config[\"temperature\"] = 1.0\n",
    "llm_config.gen_config[\"top_p\"] = 0.95\n",
    "llm_config.gen_config[\"context_length\"] = 0\n",
    "llm_config.gen_config[\"max_tokens\"] = 384\n",
    "llm_config.gen_config[\"stop_token\"] = None\n",
    "llm_config.gen_config[\"max_obs_length\"] = 3840\n",
    "llm_config.gen_config[\"max_retry\"] = 1\n",
    "llm_tokenizer = Tokenizer(\n",
    "    model_name=\"gpt-4o\",\n",
    "    provider=os.environ['PROVIDER']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import lzma\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cachetools import Cache\n",
    "from PIL import Image\n",
    "from browser_env.utils import StateInfo, pil_to_b64\n",
    "from src.helper_functions import get_action_description\n",
    "from src.envs.actions import Action\n",
    "\n",
    "\n",
    "IMAGE_CAPTION_CACHE = Cache(maxsize=1000)\n",
    "\n",
    "cache_save_path = \"ft_image_cache.pkl\"\n",
    "# save this cache\n",
    "if os.path.exists(cache_save_path):\n",
    "    with open(cache_save_path, \"rb\") as fread:\n",
    "        IMAGE_CAPTION_CACHE.update(pickle.load(fread))\n",
    "    print(f\"Loaded {len(IMAGE_CAPTION_CACHE)} cache entries\")\n",
    "\n",
    "def save_image_cache():\n",
    "    with open(cache_save_path, \"wb\") as fwrite:\n",
    "        pickle.dump(IMAGE_CAPTION_CACHE, fwrite)\n",
    "    print(f\"Saved {len(IMAGE_CAPTION_CACHE)} cache entries\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.evaluation import image_utils\n",
    "\n",
    "def configure_captioning_fn():\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    caption_image_fn = image_utils.get_captioning_fn(\n",
    "        device, dtype, \"Salesforce/blip2-flan-t5-xl\"\n",
    "    )\n",
    "    return caption_image_fn\n",
    "\n",
    "\n",
    "captioning_fn = configure_captioning_fn()\n",
    "\n",
    "\n",
    "def cached_caption_image_fn(images: list):\n",
    "    encoded_images_str = \"\"\n",
    "    for image in images:\n",
    "        encoded_images_str += pil_to_b64(image)\n",
    "    if encoded_images_str in IMAGE_CAPTION_CACHE:\n",
    "        return IMAGE_CAPTION_CACHE[encoded_images_str]\n",
    "    \n",
    "    captions = captioning_fn(images)\n",
    "    IMAGE_CAPTION_CACHE[encoded_images_str] = captions\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_descs(trajectory, action_set_tag: str):\n",
    "    action_strs = [\"None\"]\n",
    "    prev_state = None\n",
    "    for data in trajectory:\n",
    "        if isinstance(data, dict):\n",
    "            prev_state = data\n",
    "        else:\n",
    "            action = data\n",
    "            # observation_metadata = prev_state['info']['observation_metadata']\n",
    "            if 'obs_metadata' not in action.metadata:\n",
    "                observation_metadata = prev_state['info']['observation_metadata']\n",
    "            else:\n",
    "                observation_metadata = action.metadata['obs_metadata']\n",
    "            action_desc = get_action_description(\n",
    "                action,\n",
    "                observation_metadata=observation_metadata,\n",
    "                action_set_tag=action_set_tag,\n",
    "                prompt_constructor=None\n",
    "            )\n",
    "            action_strs.append(action_desc)\n",
    "    return action_strs\n",
    "\n",
    "\n",
    "def format_trajectory_to_chat(prompt_constructor, trajectory, last_action: Action, task_info):\n",
    "    # make sure the last one is state\n",
    "    assert isinstance(trajectory[-1], dict)\n",
    "\n",
    "    images = task_info[\"images\"]  # intent images\n",
    "    intent  = task_info[\"intent\"]\n",
    "    meta_data = {}\n",
    "\n",
    "    action_history_descs = get_action_descs(trajectory, \"id_accessibility_tree\")\n",
    "    meta_data[\"action_history\"] = action_history_descs\n",
    "\n",
    "    # Caption the input image, if provided.\n",
    "    if images is not None and len(images) > 0:\n",
    "        image_input_caption = \"\"\n",
    "        for image_i, image in enumerate(images):\n",
    "            if image_i == 0:\n",
    "                image_input_caption += f'Input image {image_i+1}: \"{cached_caption_image_fn([image])[0]}\"'\n",
    "            else:\n",
    "                image_input_caption += f'input image {image_i+1}: \"{cached_caption_image_fn([image])[0]}\"'\n",
    "            if len(images) > 1:\n",
    "                image_input_caption += \", \"\n",
    "        # Update intent to include captions of input images.\n",
    "        intent = f\"{image_input_caption}\\nIntent: {intent}\"\n",
    "\n",
    "    prompt = prompt_constructor.construct(\n",
    "        trajectory, intent, meta_data  # empty images since we use caption for training data\n",
    "    )\n",
    "    ### add final output\n",
    "    agent_resp = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": last_action.raw_prediction,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    prompt.append(agent_resp)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def flatten_to_trainable_chat(chat: list, train_last_only=False):\n",
    "    train_sample = []\n",
    "    _all_weights = []\n",
    "    for i, message in enumerate(chat):\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        if isinstance(content, list):\n",
    "            str_contents = []\n",
    "            for c in content:\n",
    "                assert c[\"type\"] == \"text\"\n",
    "                str_contents.append(c[\"text\"])\n",
    "            str_content = \"\\n\\n\".join(str_contents)\n",
    "        else:\n",
    "            assert isinstance(content, str)\n",
    "            str_content = content\n",
    "        \n",
    "        if role == \"user\":\n",
    "            train_sample.append({\n",
    "                \"role\": role,\n",
    "                \"content\": str_content\n",
    "            })\n",
    "        elif role == \"system\":\n",
    "            train_sample.append({\n",
    "                \"role\": role,\n",
    "                \"content\": str_content\n",
    "            })\n",
    "        elif role == \"assistant\":\n",
    "            if train_last_only:\n",
    "                is_last = i == len(chat) - 1\n",
    "                train_sample.append({\n",
    "                    \"role\": role,\n",
    "                    \"content\": str_content,\n",
    "                    \"weight\": 1 if is_last else 0\n",
    "                })\n",
    "                _all_weights.append(1 if is_last else 0)\n",
    "            else:\n",
    "                train_sample.append({\n",
    "                    \"role\": role,\n",
    "                    \"content\": str_content,\n",
    "                    \"weight\": 1\n",
    "                })\n",
    "                _all_weights.append(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown role {role}\")\n",
    "\n",
    "    print(f\"formatted traj length {len(train_sample)}, weights: {_all_weights}\")\n",
    "    return {\n",
    "        \"messages\": train_sample\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_trainable_chat(train_sample: dict):\n",
    "    chat = train_sample[\"messages\"]\n",
    "    for i, message in enumerate(chat):\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        print(f\"[[[Turn {i} with {role}]]]\")\n",
    "        print(f\"{content}\")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### text modality\n",
    "import argparse\n",
    "from src.agentic.policy import ExploratoryCoTPolicyPConstructor\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    instruction_path=\"../../src/prompts/vwa/jsons/p_cot_id_actree_3s_final_norefl_noicl_tree.json\",\n",
    ")\n",
    "\n",
    "prompt_constructor = ExploratoryCoTPolicyPConstructor(\n",
    "    instruction_path=args.instruction_path,\n",
    "    lm_config=llm_config,\n",
    "    tokenizer=llm_tokenizer\n",
    ")\n",
    "tree_prompt_constructor = prompt_constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_element(element_a: dict, element_b: dict):\n",
    "    a_text = element_a['text'].lower()\n",
    "    a_text = a_text[a_text.find(' ') + 1:]  # remove the [xxx] in front\n",
    "    b_text = element_b['text'].lower()\n",
    "    b_text = b_text[b_text.find(' ') + 1:]\n",
    "\n",
    "    a_words = set(a_text.split())\n",
    "    b_words = set(b_text.split())\n",
    "\n",
    "    num_similar_words = len(a_words.intersection(b_words))\n",
    "    if num_similar_words / len(a_words) >= 0.75:\n",
    "        print(f\"treating element_a={element_a['text']}, element_b={element_b['text']} as the same.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def maybe_update_action_id(action: Action, info: dict = None) -> Action:\n",
    "    assert info is not None\n",
    "    env_obs_metadata = info['observation_metadata']\n",
    "    env_obs_text_nodes_info_ = env_obs_metadata['text'].get('obs_nodes_info', {})\n",
    "    env_obs_text_nodes_info = {k: v['text'] for k, v in env_obs_text_nodes_info_.items()}\n",
    "    env_obs_som_nodes_info = env_obs_metadata['image'].get('obs_nodes_semantic_info', {})\n",
    "\n",
    "    env_obs_nodes_info = {}\n",
    "    if len(env_obs_som_nodes_info) > 0:\n",
    "        env_obs_nodes_info = env_obs_som_nodes_info\n",
    "    elif len(env_obs_text_nodes_info) > 0:\n",
    "        env_obs_nodes_info = env_obs_text_nodes_info\n",
    "    else:\n",
    "        print(f\"maybe_update_action: both text and image has no nodes, skipping\")\n",
    "        return action\n",
    "\n",
    "    # decide which action obs node it is\n",
    "    if 'obs_metadata' not in action.metadata:\n",
    "        print(f\"obs_metadata not found in action={action.to_simple_str()}, skippping\")\n",
    "        return action\n",
    "    \n",
    "    action_obs_nodes_info = {}\n",
    "    action_obs_text_nodes_info = action.metadata['obs_metadata'].get('text', {}).get('obs_nodes_info', {})\n",
    "    action_obs_som_nodes_info = action.metadata['obs_metadata'].get('image', {}).get('obs_nodes_semantic_info', {})\n",
    "    if len(action_obs_som_nodes_info) > 0:\n",
    "        action_obs_nodes_info = action_obs_som_nodes_info\n",
    "    elif len(action_obs_text_nodes_info) > 0:\n",
    "        action_obs_nodes_info = {k: v['text'] for k, v in action_obs_text_nodes_info.items()}\n",
    "\n",
    "    \n",
    "    action_element_id = action.element_id\n",
    "    if action_element_id == '':\n",
    "        return action\n",
    "    if action_element_id not in action_obs_nodes_info:\n",
    "        print(f\"action_element_id={action_element_id} not found in its own nodes={action_obs_nodes_info.keys()}, skipping\")\n",
    "        return action\n",
    "    \n",
    "    if action_element_id in env_obs_nodes_info:\n",
    "        # check if element is matched\n",
    "        env_node = {\n",
    "            'text': env_obs_nodes_info[action_element_id]\n",
    "        }\n",
    "        action_node = {\n",
    "            'text': action_obs_nodes_info[action_element_id]\n",
    "        }\n",
    "        if is_same_element(env_node, action_node):\n",
    "            return action\n",
    "        else:\n",
    "            print(f\"found element might have changed from {action_obs_nodes_info[action_element_id]} to {env_obs_nodes_info[action_element_id]}.\")\n",
    "\n",
    "    print(f'maybe_update_action trying to update action={action.to_simple_str()}')\n",
    "    print(f'maybe_update_action env_obs_nodes_info={env_obs_nodes_info.keys()}')\n",
    "    print(f'maybe_update_action action_obs_nodes_info={action_obs_nodes_info.keys()}')\n",
    "    \n",
    "    error_margin = int(0.1 * len(action_obs_nodes_info))\n",
    "    error_margin = max(1, error_margin)\n",
    "    # assume root node is the min\n",
    "    action_min_node_id = min([int(k) for k in action_obs_nodes_info.keys()])\n",
    "    action_element_id_offset = int(action_element_id) - action_min_node_id\n",
    "    env_min_node_id = min([int(k) for k in env_obs_nodes_info.keys()])\n",
    "\n",
    "    ## start from middle and search for left and right\n",
    "    is_updated = False\n",
    "    for i in range(error_margin+1):\n",
    "        possible_id = str(action_element_id_offset + env_min_node_id + i)\n",
    "        if possible_id in env_obs_nodes_info:\n",
    "            env_node = {\n",
    "                'text': env_obs_nodes_info[possible_id]\n",
    "            }\n",
    "            action_node = {\n",
    "                'text': action_obs_nodes_info[action_element_id]\n",
    "            }\n",
    "            if is_same_element(env_node, action_node):\n",
    "                # do the substitution\n",
    "                previous_raw_prediction = action.raw_prediction\n",
    "                action.metadata['previous_raw_prediction'] = previous_raw_prediction\n",
    "                action.metadata['previous_element_id'] = action_element_id\n",
    "\n",
    "                action.element_id = possible_id\n",
    "                action.metadata['obs_metadata'] = env_obs_metadata\n",
    "                action.raw_prediction = previous_raw_prediction.replace(f\"[{action_element_id}]\", f\"[{possible_id}]\")\n",
    "                print(f\"maybe_update_action updated action={action.to_simple_str()}\")\n",
    "                is_updated = True\n",
    "                break\n",
    "        \n",
    "        possible_id = str(action_element_id_offset + env_min_node_id - i)\n",
    "        if possible_id in env_obs_nodes_info:\n",
    "            env_node = {\n",
    "                'text': env_obs_nodes_info[possible_id]\n",
    "            }\n",
    "            action_node = {\n",
    "                'text': action_obs_nodes_info[action_element_id]\n",
    "            }\n",
    "            if is_same_element(env_node, action_node):\n",
    "                # do the substitution\n",
    "                previous_raw_prediction = action.raw_prediction\n",
    "                action.metadata['previous_raw_prediction'] = previous_raw_prediction\n",
    "                action.metadata['previous_element_id'] = action_element_id\n",
    "\n",
    "                action.element_id = possible_id\n",
    "                action.metadata['obs_metadata'] = env_obs_metadata\n",
    "                action.raw_prediction = previous_raw_prediction.replace(f\"[{action_element_id}]\", f\"[{possible_id}]\")\n",
    "                print(f\"maybe_update_action updated action={action.to_simple_str()}\")\n",
    "                is_updated = True\n",
    "                break\n",
    "    if not is_updated:\n",
    "        print(f\"maybe_update_action failed to update action.\")\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 cache entries\n"
     ]
    }
   ],
   "source": [
    "from src.constants import SIMPLE_LLM_API_CACHE\n",
    "\n",
    "SIMPLE_LLM_API_CACHE = Cache(maxsize=1000)\n",
    "\n",
    "llm_cache_save_path = \"llm_api_cache.pkl\"\n",
    "# save this cache\n",
    "if os.path.exists(llm_cache_save_path):\n",
    "    with open(llm_cache_save_path, \"rb\") as fread:\n",
    "        SIMPLE_LLM_API_CACHE.update(pickle.load(fread))\n",
    "    print(f\"Loaded {len(SIMPLE_LLM_API_CACHE)} cache entries\")\n",
    "\n",
    "def save_llm_cache():\n",
    "    with open(llm_cache_save_path, \"wb\") as fwrite:\n",
    "        pickle.dump(SIMPLE_LLM_API_CACHE, fwrite)\n",
    "    print(f\"Saved {len(SIMPLE_LLM_API_CACHE)} cache entries\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from browser_env.env_config import URL_MAPPINGS\n",
    "\n",
    "def map_url_to_real(url: str) -> str:\n",
    "    \"\"\"Map the urls to their real world counterparts\"\"\"\n",
    "    for i, j in URL_MAPPINGS.items():\n",
    "        if i in url:\n",
    "            url = url.replace(i, j)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import copy\n",
    "from src.agentic.value_function import create_chat_completion_wrapper\n",
    "\n",
    "DSET_NAME_TO_FOLDER = {\n",
    "    \"classifields\": \"../../configs/visualwebarena/test_classifieds_v2\",\n",
    "    \"reddit\": \"../../configs/visualwebarena/test_reddit_v2\",\n",
    "    \"shopping\": \"../../configs/visualwebarena/test_shopping_v2\"\n",
    "}\n",
    "\n",
    "\n",
    "def _traj_preprocessing(traj):\n",
    "    # pop last state until its an action\n",
    "    traj_copy = copy.deepcopy(traj)\n",
    "    while not isinstance(traj_copy[-1], Action):\n",
    "        traj_copy.pop()\n",
    "    return traj_copy\n",
    "\n",
    "\n",
    "def _filter_train_data(formatted_chat):\n",
    "    error_kwd = \"no matching element found\"\n",
    "    reflection_kwd = \"reflections\"\n",
    "    if error_kwd in formatted_chat[-1][\"content\"]:\n",
    "        return True # remove\n",
    "    \n",
    "    # last assistant turn is not empty (e.g. no errors)\n",
    "    last_turn = formatted_chat[-1]\n",
    "    assert last_turn[\"role\"] == \"assistant\"\n",
    "    if last_turn[\"content\"].strip() == \"\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "REPHRASE_REFL_PRMOPT = \"\"\"\n",
    "Below are some texts that are generated using model self-reflection, which provides hints on how to perform better on a web task.\n",
    "Please rephrase the following text to make it:\n",
    "1. sound natural even WITHOUT the word \"reflections\" appearing in text.\n",
    "2. to make it sound natural, you can consider converting these reflections/insights into your own thinking (see example 1 below).\n",
    "3. do NOT alter the overall meaning of the text, as well as the actions inside ```click [xx]```, ```type \"xxx\"```, etc.\n",
    "4. do NOT generate anything after rephrasing 2.\n",
    "\n",
    "For example:\n",
    "## Original 1:\n",
    "Given the reflections, it would be more efficient to navigate directly through the relevant category link rather than using the search box. Since we need to find the most recent painting in the \"Arts + crafts\" category, I will first click on the \"Arts + crafts\" category link.\n",
    "\n",
    "In summary, the next action I will perform is ```click [34]```\n",
    "## Rephrasing 1 without reflections:\n",
    "Maybe it is more efficient to navigate directly through the relevant category link rather than using the search box. Since we need to find the most recent painting in the \"Arts + crafts\" category, I will first click on the \"Arts + crafts\" category link.\n",
    "\n",
    "In summary, the next action I will perform is ```click [34]```\n",
    "\n",
    "## Original 2:\n",
    "{original_text}\n",
    "## Rephrasing 2 without reflections:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def _rephrase_reflection_content(prediction_str: str):\n",
    "    try:\n",
    "        original_exec = re.search(r\"```(.+)```\", prediction_str).group(1)\n",
    "        completion = create_chat_completion_wrapper(\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": REPHRASE_REFL_PRMOPT.format(original_text=prediction_str.strip())\n",
    "            }],\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "            top_p=0.95,\n",
    "            num_outputs=1,\n",
    "        )\n",
    "        rephrased_exec = re.search(r\"```(.+)```\", completion).group(1)\n",
    "        assert original_exec == rephrased_exec, f\"Original: {original_exec}, Rephrased: {rephrased_exec}\"\n",
    "        completion = completion.replace(\"## Rephrasing 2 without reflections:\", \"\").strip()\n",
    "\n",
    "        print(f\"rephrased from {prediction_str}\\nto\\n{completion}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        completion = prediction_str\n",
    "    return completion\n",
    "\n",
    "\n",
    "def _find_all_links(text: str) -> list:\n",
    "    links = []\n",
    "    # assume http:// or https://, ends with either space or ]\n",
    "    link_pattern = re.compile(r\"https?://[^\\s\\]]+\")\n",
    "    for match in link_pattern.finditer(text):\n",
    "        link = match.group()\n",
    "        links.append(link)\n",
    "    return links\n",
    "\n",
    "def _replace_links(text: str) -> str:\n",
    "    found_links = _find_all_links(text)\n",
    "    for link in found_links:\n",
    "        text = text.replace(link, map_url_to_real(link))\n",
    "    return text\n",
    "\n",
    "\n",
    "def _trainable_chat_postprocessing(trainable_chat, no_rephrase=False):\n",
    "    # e.g., rephrase the reflection data\n",
    "    messages = trainable_chat[\"messages\"]\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"assistant\":\n",
    "            ## rephrase reflection content\n",
    "            if \"reflection\" in m[\"content\"].lower() and not no_rephrase:\n",
    "                m[\"content\"] = _rephrase_reflection_content(m[\"content\"])\n",
    "            # though raw action data contains real urls, PARAPHRASED REFLECTIONS can sometimes leak it\n",
    "            m[\"content\"] = _replace_links(m[\"content\"])\n",
    "\n",
    "    # check last turn\n",
    "    last_turn = messages[-1]\n",
    "    assert last_turn[\"role\"] == \"assistant\"\n",
    "    assert \"reflections\" not in last_turn[\"content\"].lower()\n",
    "    return trainable_chat\n",
    "\n",
    "\n",
    "def get_single_training_data_from_trajectory(trajectory, tid: int, dset_name: str, prompt_constructor, modality='som_no_image'):\n",
    "    assert modality in ['som_no_image', 'text']\n",
    "    traj_before_last_action = trajectory[:-1]\n",
    "    last_action = trajectory[-1]\n",
    "\n",
    "    eval_config_file = f\"{DSET_NAME_TO_FOLDER[dset_name]}/{tid}.json\"\n",
    "    if not os.path.exists(eval_config_file):\n",
    "        raise Exception(f\"Cannot find {eval_config_file}\")\n",
    "    \n",
    "    with open(eval_config_file, \"r\") as fread:\n",
    "        eval_config = json.load(fread)\n",
    "\n",
    "    images = []\n",
    "    intent_image = eval_config.get(\"image\", None)\n",
    "    if intent_image is not None:\n",
    "        if not isinstance(intent_image, list):\n",
    "            image_paths = [intent_image]\n",
    "        else:\n",
    "            image_paths = intent_image\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            # Load image either from the web or from a local path.\n",
    "            if image_path.startswith(\"http\"):\n",
    "                req = requests.get(\n",
    "                    image_path,\n",
    "                    headers={\"User-Agent\": \"Mozilla/5.0\"},\n",
    "                    stream=True\n",
    "                )\n",
    "                input_image = Image.open(req.raw)\n",
    "            else:\n",
    "                input_image = Image.open(image_path)\n",
    "            images.append(input_image)\n",
    "    task_info = {\n",
    "        \"intent\": eval_config[\"intent\"],\n",
    "        \"images\": images\n",
    "    }\n",
    "\n",
    "    print('Using prompt constructor:', prompt_constructor)\n",
    "\n",
    "    if modality == 'text':\n",
    "        chat_histroy = format_trajectory_to_chat(\n",
    "            prompt_constructor,\n",
    "            traj_before_last_action,\n",
    "            last_action,\n",
    "            task_info\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unknown modality {modality}\")\n",
    "        chat_histroy = format_trajectory_to_chat(\n",
    "            prompt_constructor_text_modality,\n",
    "            traj_before_last_action,\n",
    "            last_action,\n",
    "            task_info\n",
    "        )\n",
    "\n",
    "    trainable_chat = flatten_to_trainable_chat(chat_histroy, train_last_only=True)\n",
    "    return trainable_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def check_format_errors(dataset: list[dict]):\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "\n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "            \n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "                \n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            \n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format tree data\n",
    "\n",
    "Algorithm: given an executed trajectory (s,a,s,a,...)\n",
    "\n",
    "for each (s,a) in trajectory:\n",
    "1. replay MCTS process of (s) to get traversal until that action (a)\n",
    "2. append travesal to the list of traversals\n",
    "3. format that into a flat trajectory (with backtrack formatting, etc.)\n",
    "4. append to buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get all subtress for a given correct task id\n",
    "import numpy as np\n",
    "import lzma\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "def find_successful_traj_w_trees(base_dir: str):\n",
    "    search_tree_dir = os.path.join(base_dir, \"search_trees\")\n",
    "    perf_dir = os.path.join(base_dir, \"performances\")\n",
    "    log_file_dir = os.path.join(base_dir, \"log_files\")  # check if task is correct\n",
    "    traj_file_dir = os.path.join(base_dir, \"trajectories\")\n",
    "\n",
    "    found_data = []\n",
    "    for found_search_trees in os.listdir(search_tree_dir):\n",
    "        # check if it is a folder\n",
    "        search_tree_folder = os.path.join(search_tree_dir, found_search_trees)\n",
    "        if not os.path.isdir(search_tree_folder):\n",
    "            continue\n",
    "        # e.g., task_101/\n",
    "        task_id = int(found_search_trees.split(\"_\")[-1])\n",
    "\n",
    "        ### 1. check if it is successful\n",
    "        perf_file = os.path.join(perf_dir, f\"performance_{task_id}.json\")\n",
    "        log_file = os.path.join(log_file_dir, f\"task_{task_id}.log.txt\")\n",
    "        if os.path.exists(perf_file):\n",
    "            # if has perf file, use it\n",
    "            with open(perf_file, \"r\") as fread:\n",
    "                perf = json.load(fread)\n",
    "\n",
    "            success = perf[\"scores\"] == 1.0\n",
    "            if not success:\n",
    "                continue\n",
    "        elif os.path.exists(log_file):\n",
    "            # if has log file, use it\n",
    "            with open(log_file, \"r\") as fread:\n",
    "                log = fread.read()\n",
    "\n",
    "            success = \"[Result] (PASS)\" in log\n",
    "            if not success:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Log or perf file not found for {task_id}\")\n",
    "            continue\n",
    "        \n",
    "        ### obtain the actual executed trajectory file\n",
    "        traj_fpath = os.path.join(traj_file_dir, f\"task_{task_id}.pkl.xz\")\n",
    "        if not os.path.exists(traj_fpath):\n",
    "            print(f\"Trajectory file not found for {task_id}\")\n",
    "            continue\n",
    "        with lzma.open(traj_fpath, \"rb\") as fread:\n",
    "            traj = pickle.load(fread)\n",
    "\n",
    "        all_trees_pickle_files = []\n",
    "        for file in os.listdir(search_tree_folder):\n",
    "            if file.endswith(\".pkl.xz\"):\n",
    "                all_trees_pickle_files.append(file)\n",
    "        # sort by date\n",
    "        # tree_20240921-225009.pkl.xz\n",
    "        # convert 20240921-225009 to timestamp\n",
    "        all_time_stamps = []\n",
    "        for tree_file in all_trees_pickle_files:\n",
    "            time_stamp = tree_file.split(\"_\")[-1].split(\".\")[0]\n",
    "            all_time_stamps.append(time_stamp)\n",
    "        sorted_idx = np.argsort(all_time_stamps)\n",
    "        sorted_trees = []\n",
    "        for i in sorted_idx:\n",
    "            tree_fpath = os.path.join(search_tree_folder, all_trees_pickle_files[i])\n",
    "            with lzma.open(tree_fpath, \"rb\") as fread:\n",
    "                tree = pickle.load(fread)\n",
    "            sorted_trees.append(tree)\n",
    "        \n",
    "\n",
    "        found_data.append({\n",
    "            \"task_id\": task_id,\n",
    "            \"traj\": traj,\n",
    "            \"trees\": sorted_trees\n",
    "        })\n",
    "    print(f\"Found {len(found_data)} successful tasks\")\n",
    "    return found_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name = \"classifields\"\n",
    "base_dir = \"../../data/visualwebarena/eval_results/rmcts/<eval_path>_classifields\"\n",
    "# dset_name = \"reddit\"\n",
    "# base_dir = \"../../data/visualwebarena/eval_results/rmcts/<eval_path>_reddit\"\n",
    "# dset_name = \"shopping\"\n",
    "# base_dir = \"../../data/visualwebarena/eval_results/rmcts/<eval_path>_shopping\"\n",
    "\n",
    "successful_data = find_successful_traj_w_trees(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "from src.envs.actions import Action\n",
    "from src.agent.mcts_agent import Node\n",
    "from collections import defaultdict\n",
    "from src.envs.actions import ActionTypes\n",
    "from browser_env.env_config import URL_MAPPINGS\n",
    "import re\n",
    "\n",
    "\n",
    "def _fake_simulation(state: Node):\n",
    "    # no-op since we have already done the simulation\n",
    "    return\n",
    "\n",
    "\n",
    "def _fake_expansion(state: Node, Ns, Nsa, Q):\n",
    "    # add back children\n",
    "    state.children = state._children\n",
    "\n",
    "    hashable_state = state._to_string_rep()\n",
    "\n",
    "    Ns[hashable_state] = 0\n",
    "    Nsa[hashable_state] = defaultdict(lambda: 0.0)\n",
    "    Q[hashable_state] = defaultdict(lambda: 0.0)  # 0.0 for Q[s][new_a]\n",
    "    # P is already precomputed\n",
    "    return\n",
    "\n",
    "\n",
    "def _replay_tree_traversal(\n",
    "    state: Node,\n",
    "    traversal_buffer: list,\n",
    "    Q: dict,\n",
    "    Ns: dict,\n",
    "    Nsa: dict\n",
    "):\n",
    "    # replay MCTS tree traversal until end_action is hit\n",
    "    hashable_state = state._to_string_rep()\n",
    "    \n",
    "    v = 0.0\n",
    "    # if this leaf node is terminal, return the value\n",
    "    if state.is_terminal:\n",
    "        # terminal node\n",
    "        if state._need_evaluation:\n",
    "            _fake_simulation(state)\n",
    "        return state.value\n",
    "    elif state.value == 1.0:\n",
    "        return state.value\n",
    "    elif len(state.children) == 0:\n",
    "        # selected leaf node, expand and simulate (for backprop below)\n",
    "        _fake_expansion(state, Ns, Nsa, Q)\n",
    "        _fake_simulation(state)\n",
    "        return state.value\n",
    "    \n",
    "    ##### Selection\n",
    "    # existing, continue selection\n",
    "    # go next state by picking best according to U(s,a)\n",
    "    cpuct = 1.0\n",
    "    best_uct = -float('inf')\n",
    "    best_action = None\n",
    "    for a in state.children.keys():\n",
    "        _Ns = Ns[hashable_state]\n",
    "        _qsa = Q[hashable_state][a]\n",
    "        _p = a.metadata[\"P\"]\n",
    "        _nsa = Nsa[hashable_state][a]\n",
    "        if Ns == 0:  # first time visit\n",
    "            uct = _qsa + cpuct * _p\n",
    "        else:\n",
    "            uct = _qsa + cpuct * _p * math.sqrt(_Ns) / (1 + _nsa)\n",
    "        \n",
    "        if uct > best_uct:\n",
    "            best_uct = uct\n",
    "            best_action = a\n",
    "            print(f\"updating best action: {best_action.raw_prediction}\")\n",
    "            print(f\"uct={uct} (with {_Ns=}, {_nsa=}, {_qsa=}, {_p=})\")\n",
    "    print(f\"selected best action: {best_action.raw_prediction}\")\n",
    "    \n",
    "    # transition and update that state's metadata\n",
    "    # best_action_cache.append(best_action)\n",
    "    # next_state = await self._get_next_state(state, best_action)\n",
    "    next_state = state.children[best_action]\n",
    "    \n",
    "    ##### Expansion and Simulation\n",
    "    # 1. if not leaf, continue traversing, and state=s will get the value from the leaf node\n",
    "    # 2. if leaf, we will expand it and return the value for backpropagation\n",
    "    v = _replay_tree_traversal(\n",
    "        next_state,\n",
    "        traversal_buffer,\n",
    "        Q,\n",
    "        Ns,\n",
    "        Nsa\n",
    "    )\n",
    "\n",
    "    ##### Backpropagation\n",
    "    # update stats\n",
    "    # add in new estimate and average\n",
    "    Q[hashable_state][best_action] = (Nsa[hashable_state][best_action] * Q[hashable_state][best_action] + v) / (Nsa[hashable_state][best_action] + 1)\n",
    "    print(f\"backpropagating value {v} to get Q[{hashable_state}][{best_action.raw_prediction}]={Q[hashable_state][best_action]}\")\n",
    "    Nsa[hashable_state][best_action] += 1\n",
    "    Ns[hashable_state] += 1\n",
    "    state.Ns += 1\n",
    "\n",
    "    # update metadata in action\n",
    "    best_action.metadata[\"Q\"] = Q[hashable_state][best_action]\n",
    "    best_action.metadata[\"Nsa\"] = Nsa[hashable_state][best_action]\n",
    "    best_action.metadata[\"V_next\"] = next_state.value\n",
    "    \n",
    "    if len(next_state.trajectory) == 0:\n",
    "        traversal_buffer.insert(1, next_state)  # the 0ths root state should be untouched\n",
    "    else:\n",
    "        traversal_buffer.insert(1, next_state.trajectory[-1])  # the 0ths root state should be untouched\n",
    "    traversal_buffer.insert(1, best_action)\n",
    "\n",
    "    ### check if action is found\n",
    "    element_id = best_action.element_id\n",
    "    if element_id != '':\n",
    "        if not state.is_terminal:\n",
    "            elemnt_text = f\"[{element_id}]\"\n",
    "            state_dict = state.trajectory[-1]\n",
    "            state_obs_text = state_dict['observation']['text']\n",
    "            action_nodes = best_action.metadata['obs_metadata']['text']['obs_nodes_info']\n",
    "            if elemnt_text in state_obs_text:\n",
    "                print(f\"{elemnt_text=} is found in current state\")\n",
    "            else:\n",
    "                print(f\"{elemnt_text=} is NOT found in current state\")\n",
    "                if element_id in action_nodes:\n",
    "                    print(f\"{element_id=} is found in action nodes\")\n",
    "                else:\n",
    "                    print(f\"{element_id=} is NOT found in action nodes\")\n",
    "    return v\n",
    "\n",
    "\n",
    "def _prepare_fake_tree(root: Node):\n",
    "    # temporary reset all stats\n",
    "    root._Ns = root.Ns\n",
    "    root.Ns = 0\n",
    "\n",
    "    all_a_s = root._get_all_child_actions()\n",
    "    for a, s in all_a_s:\n",
    "        s._Ns = s.Ns\n",
    "        s.Ns = 0\n",
    "        s._children = s.children\n",
    "        s.children = {}\n",
    "    \n",
    "    root._children = root.children\n",
    "    root.children = {}\n",
    "    return root\n",
    "\n",
    "def __non_numeric_words(state_text):\n",
    "    words = []\n",
    "    for w in state_text.split():\n",
    "        if re.match(r\"\\[\\d+\\]\", w):\n",
    "            continue\n",
    "        words.append(w)\n",
    "    return words\n",
    "\n",
    "\n",
    "def _is_state_similar(state1, state2):\n",
    "    if state1 is None and state2 is None:\n",
    "        print('received two None actions')\n",
    "        return True\n",
    "    if state1 is None or state2 is None:\n",
    "        return False\n",
    "    state1_text = state1['observation']['text']\n",
    "    state2_text = state2['observation']['text']\n",
    "    state_1words = __non_numeric_words(state1_text)\n",
    "    state_2words = __non_numeric_words(state2_text)\n",
    "    \n",
    "    num_overlap_words = len(set(state_1words).intersection(set(state_2words)))\n",
    "    total_words = len(set(state_1words).union(set(state_2words)))\n",
    "    print(f\"overlap words: {num_overlap_words}, total words: {total_words}, ratio: {num_overlap_words / total_words}\")\n",
    "    return num_overlap_words / total_words > 0.9\n",
    "\n",
    "\n",
    "def _is_action_similar(action1: Action, action2: Action):\n",
    "    if action1 is None and action2 is None:\n",
    "        print('received two None actions')\n",
    "        return True\n",
    "    if action1 is None or action2 is None:\n",
    "        return False\n",
    "    action1_text = action1.raw_prediction\n",
    "    action1_element_id = action1.element_id\n",
    "    action2_text = action2.raw_prediction\n",
    "    action2_element_id = action2.element_id\n",
    "    action1_text = action1_text.replace(f\"[{action1_element_id}]\", \"[X]\")\n",
    "    action2_text = action2_text.replace(f\"[{action2_element_id}]\", \"[X]\")\n",
    "\n",
    "    print(f'checking similarity between\\n{action1_text}\\nand\\n{action2_text}')\n",
    "    print('result, they are similar:', action1_text.strip() == action2_text.strip())\n",
    "    return action1_text.strip() == action2_text.strip()\n",
    "\n",
    "\n",
    "def _is_trajectory_similar(traj1, traj2):\n",
    "    if len(traj1) != len(traj2):\n",
    "        return False\n",
    "    \n",
    "    for data1, data2 in zip(traj1, traj2):\n",
    "        if isinstance(data1, dict) and isinstance(data2, dict):\n",
    "            if not _is_state_similar(data1, data2):\n",
    "                return False\n",
    "        elif isinstance(data1, Action) and isinstance(data2, Action):\n",
    "            if not _is_action_similar(data1, data2):\n",
    "                return False\n",
    "        elif isinstance(data1, Node) and isinstance(data2, Node):\n",
    "            if data1.is_terminal != data2.is_terminal:\n",
    "                return False\n",
    "            if data1.is_terminal == data2.is_terminal:\n",
    "                print('both are terminal, assuming same state')\n",
    "                return True\n",
    "            if not _is_state_similar(data1.trajectory[-1], data2.trajectory[-1]):\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def replay_tree_traversal(single_tree: Node, traversal_buffer: list, end_action: Action):\n",
    "    Q = {}  # new stats\n",
    "    Ns = {}  # new stats\n",
    "    Nsa = {}  # new stats\n",
    "\n",
    "    found_last_action = False\n",
    "\n",
    "    tmp_tree = copy.deepcopy(single_tree)\n",
    "\n",
    "    tmp_tree = _prepare_fake_tree(tmp_tree)\n",
    "\n",
    "    itr = 50\n",
    "    start_state = tmp_tree.trajectory[-1]\n",
    "    _replay_tree_traversal(tmp_tree, [], Q, Ns, Nsa)  # init root node\n",
    "    print('traversal start, looking for ', end_action.raw_prediction)\n",
    "    print(f'root node has {len(single_tree.children)} children')\n",
    "    while not found_last_action:\n",
    "        curr_traversal = [start_state]\n",
    "        _replay_tree_traversal(tmp_tree, curr_traversal, Q, Ns, Nsa)\n",
    "        assert len(curr_traversal) >= 2, f\"curr_traversal: {curr_traversal}\"\n",
    "        if len(curr_traversal) >= 2:\n",
    "            last_action = curr_traversal[-2]\n",
    "            if _is_action_similar(last_action, end_action):\n",
    "                found_last_action = True\n",
    "                print(f'found last action in {50-itr+1} iterations')\n",
    "        # curr_traversal.pop()  # we want to end with (s,a,s)\n",
    "\n",
    "        traversal_buffer.append(curr_traversal)\n",
    "        itr -= 1\n",
    "        if itr < 0:\n",
    "            print(\"Max iteration reached\")\n",
    "            break\n",
    "    return traversal_buffer\n",
    "\n",
    "\n",
    "def __print_traj(traj):\n",
    "    concat_str = 'None'\n",
    "    for data in traj:\n",
    "        if isinstance(data, Action):\n",
    "            concat_str += f\"\\n---->\\n{data.raw_prediction}\"\n",
    "    print(concat_str)\n",
    "    return\n",
    "\n",
    "\n",
    "def __find_common_ancestor_idx(trav1: list, trav2: list):\n",
    "    found_idx = 0\n",
    "    for idx, (data_1, data_2) in enumerate(zip(trav1, trav2)):\n",
    "        try:\n",
    "            assert type(data_1) == type(data_2)\n",
    "        except AssertionError:\n",
    "            raise Exception(f\"Data type mismatch: {type(data_1)} != {type(data_2)}\")\n",
    "\n",
    "        if isinstance(data_1, dict):\n",
    "            if _is_state_similar(data_1, data_2):\n",
    "                ancestor_state = data_1\n",
    "                found_idx = idx\n",
    "        elif isinstance(data_1, Action):\n",
    "            continue\n",
    "        elif isinstance(data_1, Node):\n",
    "            print('type(data_1):', data_1.is_root)\n",
    "            __print_traj(data_1.trajectory)\n",
    "            print('type(data_2) is root?', data_2.is_root)\n",
    "            __print_traj(data_2.trajectory)\n",
    "            if data_1.is_terminal and data_2.is_terminal:\n",
    "                # the only allowed possibility is that we are exploring two end actions\n",
    "                prev_action_1: Action = trav1[idx-1]\n",
    "                prev_action_2: Action = trav2[idx-1]\n",
    "                if prev_action_1.action_type != ActionTypes.STOP:\n",
    "                    raise Exception(\"Both are terminal, should not happen\")\n",
    "                if prev_action_2.action_type != ActionTypes.STOP:\n",
    "                    raise Exception(\"Both are terminal, should not happen\")\n",
    "                found_idx = idx - 1  # last state before stop\n",
    "                break\n",
    "            if data_1.is_terminal or data_2.is_terminal:\n",
    "                found_idx = idx - 1  # last state before stop\n",
    "                break\n",
    "            state_1 = data_1.trajectory[-1]\n",
    "            state_2 = data_2.trajectory[-1]\n",
    "            if _is_state_similar(state_1, state_2):\n",
    "                ancestor_state = state_1\n",
    "                found_idx = idx\n",
    "    return found_idx\n",
    "\n",
    "def _find_common_ancestor(trav1: list, trav2: list):\n",
    "    ancestor_state_idx = __find_common_ancestor_idx(trav1, trav2)\n",
    "    ancestor_state = trav1[ancestor_state_idx]\n",
    "    return ancestor_state\n",
    "\n",
    "\n",
    "def _fastforward_target_to_common_ancestor(trav1: list, trav2: list):\n",
    "    # same loop as find ancestor, but return the remaining of trav2\n",
    "    trav2_no_laststate = trav2[:-1]\n",
    "    skipped_idx = __find_common_ancestor_idx(trav1, trav2_no_laststate)\n",
    "    return trav2[skipped_idx+1:]  # start with action\n",
    "\n",
    "\n",
    "def _backtrack_to_common_ancestor(traversal: list, trav2: list, flattened_traj_so_far: list):\n",
    "    # same loop as find ancestor, but return the remaining of trav2\n",
    "    trav2_no_laststate = trav2[:-1]\n",
    "    skipped_idx = __find_common_ancestor_idx(traversal, trav2_no_laststate)\n",
    "    # (s0, a0, s1, a1, s2), ancestor s1, then this is (s1, a1)\n",
    "    action_state_to_reverse = traversal[skipped_idx:-1]  # keep first state and remove last state\n",
    "    ancestor_state = traversal[skipped_idx]\n",
    "\n",
    "    num_actions_to_reverse = 0\n",
    "    num_stop_actions_to_reverse = 0\n",
    "    for i, data in enumerate(action_state_to_reverse):\n",
    "        if isinstance(data, Action):\n",
    "            direction = getattr(data, '_direction', '')\n",
    "            if direction == 'backtrack':\n",
    "                if getattr(data, '_n_action_reversed', None) is None:\n",
    "                    raise Exception(\"_n_action_reversed not inside action\")\n",
    "                num_actions_to_reverse -= data._n_action_reversed\n",
    "            else:\n",
    "                num_actions_to_reverse += 1\n",
    "            # special case\n",
    "            action_type = data.action_type\n",
    "            if action_type == ActionTypes.STOP:\n",
    "                num_stop_actions_to_reverse += 1\n",
    "    if num_actions_to_reverse < 0:\n",
    "        raise Exception(\"Negative number of actions to reverse\")\n",
    "    \n",
    "    if num_actions_to_reverse == 0:\n",
    "        return flattened_traj_so_far\n",
    "    elif num_actions_to_reverse > 1:\n",
    "        # jump to url\n",
    "        tmp_action: Action = copy.deepcopy(action_state_to_reverse[1])\n",
    "        state_to_go_to = copy.deepcopy(ancestor_state)\n",
    "        if not isinstance(state_to_go_to, dict):\n",
    "            # cannt be right\n",
    "           raise Exception(\"state_to_go_to is not a state\")\n",
    "\n",
    "        # remove stop actions\n",
    "        if num_stop_actions_to_reverse == 1:\n",
    "            # only makes sense if its the last action\n",
    "            last_action_dtype = action_state_to_reverse[-1].action_type\n",
    "            if last_action_dtype != ActionTypes.STOP:\n",
    "                raise Exception(\"STOP action is not the last action\")\n",
    "            flattened_traj_so_far.pop()  # pop node and action in traversal and directly goto\n",
    "            flattened_traj_so_far.pop()\n",
    "        elif num_stop_actions_to_reverse > 1:\n",
    "            raise Exception(\"More than one stop action to reverse\")\n",
    "        \n",
    "        raw_url = state_to_go_to['url']\n",
    "        real_url = map_url_to_real(raw_url)\n",
    "        state_to_go_to['_direction'] = 'backtrack'\n",
    "        tmp_action.raw_prediction = f\"```goto [{real_url}]```\"\n",
    "        tmp_action.action_type = ActionTypes.GOTO_URL\n",
    "        tmp_action.element_id = ''\n",
    "        tmp_action._n_action_reversed = num_actions_to_reverse\n",
    "        tmp_action._direction = 'backtrack'\n",
    "        tmp_action._backtrack_url = real_url\n",
    "        \n",
    "        flattened_traj_so_far.append(tmp_action)\n",
    "        flattened_traj_so_far.append(state_to_go_to)\n",
    "    else:\n",
    "        # one action, just do ```go_back```\n",
    "        # action_state_afterwards contains (a->s)\n",
    "        # may need to deal with STOP action -> end state\n",
    "        action: Action = copy.deepcopy(action_state_to_reverse[1])\n",
    "        state = action_state_to_reverse[0]\n",
    "\n",
    "        if action.action_type == ActionTypes.NONE:\n",
    "            # beautiful, no-op\n",
    "            return flattened_traj_so_far\n",
    "        elif action.action_type == ActionTypes.STOP:\n",
    "            # remove action from traversal\n",
    "            if len(traversal) < 2:\n",
    "                raise Exception(f\"WTF is inside traversal??? {traversal=}\")\n",
    "            if traversal[-2].action_type != ActionTypes.STOP:\n",
    "                raise Exception(\"STOP action is not followed by STOP action\")\n",
    "            flattened_traj_so_far.pop() # pop state\n",
    "            flattened_traj_so_far.pop() # pop action\n",
    "        else:\n",
    "            # normal action\n",
    "            action._direction = 'backtrack'\n",
    "            action._n_action_reversed = 1\n",
    "            action.element_id = ''\n",
    "            flattened_traj_so_far.append(action)\n",
    "            state['_direction'] = 'backtrack'\n",
    "            flattened_traj_so_far.append(state)\n",
    "    return flattened_traj_so_far\n",
    "\n",
    "\n",
    "def post_process_traversal(traversal: list):\n",
    "    if len(traversal) == 1:\n",
    "        # next action is the best\n",
    "        flattened = traversal[0]\n",
    "        assert len(flattened) == 3\n",
    "        assert not isinstance(flattened[-1], Action)\n",
    "        flattened.pop()  # remove the last state\n",
    "        assert isinstance(flattened[-1], Action)\n",
    "        return flattened\n",
    "    \n",
    "    ### remove consecutive, duplicate trajectories. These correspond to many iterations to reduce exploitation\n",
    "    new_traversal = [traversal[0]]\n",
    "    prev_trav = traversal[0]\n",
    "    for i in range(1, len(traversal)):\n",
    "        curr_trav = traversal[i]\n",
    "        # if prev_trav != curr_trav:\n",
    "        if not _is_trajectory_similar(prev_trav, curr_trav):\n",
    "            new_traversal.append(curr_trav)\n",
    "        prev_trav = curr_trav\n",
    "\n",
    "    ### work with this traversal, so that its a single list of (s,a,s,a,...,a)\n",
    "    flattened_w_backtrack = new_traversal[0]  # start with (s,a,s)\n",
    "    \n",
    "    ## algo:\n",
    "    ## no backtracking when current action's parent == previous action\n",
    "    ## backtracking occurs otherwise -> find current action and prev action's common ancestor\n",
    "    ##   replay prev_action back to that ancestor,\n",
    "    ##   play current action from that ancestor\n",
    "    ## TODO!\n",
    "    for i in range(1, len(new_traversal)):\n",
    "        curr_trav = new_traversal[i]\n",
    "\n",
    "        print(f'working on prev traj {len(flattened_w_backtrack)=}')\n",
    "        __print_traj(flattened_w_backtrack)\n",
    "        print(f'working on curr traj {len(curr_trav)=}')\n",
    "        __print_traj(curr_trav)\n",
    "\n",
    "        # find common ancestor state\n",
    "        prev_trav = copy.deepcopy(new_traversal[i-1])\n",
    "        common_ancestor_state = _find_common_ancestor(prev_trav, curr_trav[:-1])\n",
    "        \n",
    "        _backtrack_to_common_ancestor(prev_trav, curr_trav, flattened_traj_so_far=flattened_w_backtrack)\n",
    "        curr_trav = _fastforward_target_to_common_ancestor(prev_trav, curr_trav)\n",
    "        \n",
    "        for data in curr_trav:\n",
    "            if isinstance(data, tuple):\n",
    "                data, _ = data\n",
    "            ### check if we found it already\n",
    "            if isinstance(data, dict):\n",
    "                data['_direction'] = 'forward'\n",
    "            else:\n",
    "                data._direction = 'forward'\n",
    "            flattened_w_backtrack.append(data)\n",
    "    return flattened_w_backtrack\n",
    "\n",
    "\n",
    "def process_single_traj(traj, trees: list):\n",
    "    # check num states we can replay\n",
    "    s_a_pairs_to_replay = []\n",
    "    for i in range(0, len(traj), 2):\n",
    "        if i+1 >= len(traj):\n",
    "            break\n",
    "        s_a_pairs_to_replay.append((traj[i], traj[i+1]))\n",
    "    if len(s_a_pairs_to_replay) != len(trees):\n",
    "        # maybe there is fastforwarding due to V=1.0\n",
    "        last_action = s_a_pairs_to_replay[-1][1]\n",
    "        V_next = last_action.metadata.get(\"V_next\", 0.0)\n",
    "        assert V_next == 1.0, f\"V_next={V_next}\"\n",
    "\n",
    "        s_a_pairs_to_replay_ = []\n",
    "        # fix the traversal\n",
    "        i = -1\n",
    "        for i in range(len(trees)-1):\n",
    "            s_a_pairs_to_replay_.append(s_a_pairs_to_replay[i])\n",
    "        fast_state = s_a_pairs_to_replay[i+1][0]\n",
    "        s_a_pairs_to_replay_.append((fast_state, last_action))\n",
    "\n",
    "        s_a_pairs_to_replay = s_a_pairs_to_replay_\n",
    "    \n",
    "    # replay the tree traversal\n",
    "    all_traversals = []\n",
    "    for s_a, tree in zip(s_a_pairs_to_replay, trees):\n",
    "        state, action = s_a\n",
    "        traversal_buffer = []\n",
    "        # check if state is the same as tree's root\n",
    "        state_text = state['observation']['text']\n",
    "        tree_text = tree.trajectory[-1]['observation']['text']\n",
    "        assert _is_state_similar(state, tree.trajectory[-1]), f\"{state_text}\\nNEQ\\n{tree_text}\"\n",
    "        \n",
    "        replay_tree_traversal(tree, traversal_buffer, action)\n",
    "        traversal_buffer = post_process_traversal(traversal_buffer)\n",
    "        all_traversals.append(traversal_buffer)\n",
    "    return all_traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "num_passed = 0\n",
    "num_failed = 0\n",
    "total_length = {}\n",
    "for i in range(len(successful_data)):\n",
    "    print('processing', i)\n",
    "    try:\n",
    "        all_traversals = process_single_traj(successful_data[i][\"traj\"], successful_data[i][\"trees\"])\n",
    "        num_passed += 1\n",
    "        curr_len = 0\n",
    "        for traversal in all_traversals:\n",
    "            curr_len += len(traversal)\n",
    "\n",
    "        if curr_len not in total_length:\n",
    "            total_length[curr_len] = 0\n",
    "        total_length[curr_len] += 1\n",
    "    except Exception as e:\n",
    "        num_failed += 1\n",
    "        print(traceback.format_exc())\n",
    "        print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in total_length.items():\n",
    "    if k < 30:\n",
    "        print(f\"length={k}, {v=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASE_BACKTRACK_PRMOPT = \"\"\"\n",
    "Below are some texts that are generated using model-model interaction in the format of:\n",
    "```\n",
    "Let's see what we have got. <Success estimate>\n",
    "We should take a step back and explore some other options.\n",
    "<action reasoning>\n",
    "```\n",
    "where the success estimate is generated by a separate model.\n",
    "\n",
    "Your task is to:\n",
    "1. rephrase the text to make it look like its generated by a single model, without any context of \"the agent\", or etc.\n",
    "2. make sure you keep the keywords such as \"Let's see what we have got\" and \"In summary\" intact.\n",
    "3. The <success estimate> and <action reasoning> should be COHERENT. If there are conflicts, you can modify the <success estimate> to make it coherent.\n",
    "4. do NOT generate aything after rephrasing 2.\n",
    "\n",
    "For example:\n",
    "## Original 1:\n",
    "Let's see what we have got. The agent's actions did not fulfill the user's intent of finding the mileage of the red car in the second row, which is the 1987 Porsche 911 Carrera. Instead, the agent navigated to the page of a different car, the 2010 Lincoln MKT, making the current state irrelevant to the user's request.\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```go_back```.\n",
    "## Rephrasing 1 as a standalone thought:\n",
    "Let's see what we have got. The current observation doesn't seem useful at fulfilling the user's intent of finding the mileage of the red car in the second row, which is the 1987 Porsche 911 Carrera. Instead, the agent navigated to the page of a different car, the 2010 Lincoln MKT, making the current state irrelevant to the user's request.\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```go_back```.\n",
    "\n",
    "## Original 2:\n",
    "{original_text}\n",
    "## Rephrasing 2 as a standalone thought:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "REPHRASE_FORWARD_PRMOPT = \"\"\"\n",
    "Below are some texts that are generated using model-model interaction in the format of:\n",
    "```\n",
    "Let's see what we have got. <Success estimate>\n",
    "\n",
    "<action reasoning>\n",
    "```\n",
    "where the success estimate is generated by a separate model.\n",
    "\n",
    "Your task is to:\n",
    "1. rephrase the text to make it look like its generated by a single model, without any context of \"the agent\", or etc.\n",
    "2. make sure you keep the keywords such as \"Let's see what we have got\" and \"In summary\" intact.\n",
    "3. The <success estimate> and <action reasoning> should be COHERENT. If there are conflicts, you can modify the <success estimate> to make it coherent.\n",
    "4. do NOT generate aything after rephrasing 2.\n",
    "\n",
    "For example:\n",
    "## Original 1:\n",
    "Let's see what we have got. The agent has navigated to a classifieds site and located a listing for \"2 Zebra Pillows,\" which matches the zebra pattern in the user\\'s intent image. The agent now just needs to navigate to that specific item's page and returning the URL.\n",
    "\n",
    "Let's think step-by-step. The objective is to find the latest listing of a pillow from the classifieds site with a pattern matching the top left animal in the first image of the listing on OneStopMarket.\n",
    "\n",
    "- From the observation, the first image on OneStopMarket is `http://coffee.cs.columbia.edu:55777/media/catalog/product/cache/829a59e57f886f8cf0598ffca4f8a940/B/0/B07T7NHZ6V.1.jpg`.\n",
    "- Based on the description, the image is of a set of animal themed cupcake toppers.\n",
    "\n",
    "In summary, the next action I will perform is ```tab_focus [1]```.\n",
    "## Rephrasing 1 as a standalone thought:\n",
    "Let's see what we have got. I have navigated to a classifieds site and located a listing for \"2 Zebra Pillows,\" which matches the zebra pattern in the user\\'s intent image. I now only need to navigate to that specific item's page and returning the URL.\n",
    "\n",
    "The objective is to find the latest listing of a pillow from the classifieds site with a pattern matching the top left animal in the first image of the listing on OneStopMarket.\n",
    "\n",
    "- From the observation, the first image on OneStopMarket is `http://coffee.cs.columbia.edu:55777/media/catalog/product/cache/829a59e57f886f8cf0598ffca4f8a940/B/0/B07T7NHZ6V.1.jpg`.\n",
    "- Based on the description, the image is of a set of animal themed cupcake toppers.\n",
    "\n",
    "In summary, the next action I will perform is ```tab_focus [1]```.\n",
    "\n",
    "## Original 2:\n",
    "{original_text}\n",
    "\n",
    "## Rephrasing 2 as a standalone thought:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def _rephrase_success_estimate(prediction_str: str, mode='backtrack'):\n",
    "    try:\n",
    "        original_exec = re.search(r\"```(.+)```\", prediction_str).group(1)\n",
    "        \n",
    "        if mode == 'backtrack':\n",
    "            content = REPHRASE_BACKTRACK_PRMOPT.format(original_text=prediction_str.strip())\n",
    "        elif mode == 'forward':\n",
    "            content = REPHRASE_FORWARD_PRMOPT.format(original_text=prediction_str.strip())\n",
    "        else:\n",
    "            raise Exception(f\"Unknown mode: {mode}\")\n",
    "        \n",
    "        completion = create_chat_completion_wrapper(\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "            top_p=0.95,\n",
    "            num_outputs=1,\n",
    "        )\n",
    "        rephrased_exec = re.search(r\"```(.+)```\", completion).group(1)\n",
    "        assert original_exec == rephrased_exec, f\"Original: {original_exec}, Rephrased: {rephrased_exec}\"\n",
    "\n",
    "        completion = completion.replace(\"## Rephrasing 2 as a standalone thought:\", \"\").strip()\n",
    "        print(f\"rephrased from {prediction_str}\\nto\\n{completion}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        completion = prediction_str\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAKCTRACK_BACK = \"\"\"\n",
    "Let's see what we have got. {judge_reasoning}\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```go_back```.\n",
    "\"\"\".strip()\n",
    "\n",
    "BAKCTRACK_SCROLL_UP = \"\"\"\n",
    "Let's see what we have got. {judge_reasoning}\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```scroll [up]```.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "BAKCTRACK_SCROLL_DOWN = \"\"\"\n",
    "Let's see what we have got. {judge_reasoning}\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```scroll [down]```.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "BAKCTRACK_GOTO_URL = \"\"\"\n",
    "Let's see what we have got. {judge_reasoning}\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```goto [{real_url}]```.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def _find_best_judge(q, judge_reasonings):\n",
    "    parsed_reasonings = {}\n",
    "\n",
    "    for reason in judge_reasonings:\n",
    "        pred = re.search(r'.*STATUS CODE: (\\w).*', reason).group(1)\n",
    "        if 'A' in pred:\n",
    "            score = 1.0\n",
    "        elif 'B' in pred:\n",
    "            score = 0.7\n",
    "        elif 'C' in pred:\n",
    "            score = 0.5\n",
    "        elif 'D' in pred:\n",
    "            score = -0.2\n",
    "        else:\n",
    "            score = -1.0\n",
    "        \n",
    "        if score not in parsed_reasonings:\n",
    "            parsed_reasonings[score] = []\n",
    "        parsed_reasonings[score].append(reason)\n",
    "    \n",
    "    # since we are backtracking, using the lower closest score\n",
    "    found_reason = \"\"\n",
    "    lowest_keys = sorted(parsed_reasonings.keys())\n",
    "    for key in lowest_keys:\n",
    "        if key > q:\n",
    "            break\n",
    "        found_reason = parsed_reasonings[key][0]\n",
    "\n",
    "    # if not found, return the lowest\n",
    "    if found_reason == \"\":\n",
    "        found_reason = parsed_reasonings[lowest_keys[0]][0]\n",
    "\n",
    "    if re.search(r\"Thoughts: (.+)\", found_reason) is None:\n",
    "        raise Exception(f\"Thoughts not found in {found_reason}\")\n",
    "\n",
    "    thought = re.search(r\"Thoughts: (.+)\", found_reason).group(1)\n",
    "    return thought\n",
    "\n",
    "\n",
    "def _process_backtrack_action(action: Action):\n",
    "    action_clone = copy.deepcopy(action)\n",
    "    # first get judge\n",
    "    additional_reasoning = _find_best_judge(\n",
    "        action.metadata[\"Q\"],\n",
    "        action.metadata[\"next_V_debate_data\"]['final_decisions']\n",
    "    )\n",
    "    assert additional_reasoning != \"\", f\"additional_reasoning is empty\"\n",
    "    \n",
    "    # reformat current action\n",
    "    action_clone.element_id = ''\n",
    "    if action_clone.action_type == ActionTypes.SCROLL:\n",
    "        if '```scroll [up]```' in action_clone.raw_prediction:\n",
    "            backtrack_raw_prediction = BAKCTRACK_SCROLL_DOWN.format(judge_reasoning=additional_reasoning)\n",
    "        elif '```scroll [down]```' in action_clone.raw_prediction:\n",
    "            backtrack_raw_prediction = BAKCTRACK_SCROLL_UP.format(judge_reasoning=additional_reasoning)\n",
    "    elif action_clone.action_type == ActionTypes.GOTO_URL:\n",
    "        # our manual setting\n",
    "        real_url = action_clone._backtrack_url\n",
    "        backtrack_raw_prediction = BAKCTRACK_GOTO_URL.format(judge_reasoning=additional_reasoning, real_url=real_url)\n",
    "    else:\n",
    "        backtrack_raw_prediction = BAKCTRACK_BACK.format(judge_reasoning=additional_reasoning)\n",
    "        action_clone.action_type = ActionTypes.GO_BACK\n",
    "    \n",
    "    rephrased = _rephrase_success_estimate(backtrack_raw_prediction)\n",
    "    action_clone.raw_prediction = rephrased\n",
    "    return action_clone\n",
    "\n",
    "\n",
    "\n",
    "FORWARD_PROMPT = \"\"\"\n",
    "Let's see what we have got. {judge_reasoning}\n",
    "\n",
    "{raw_action_prediction}\n",
    "\"\"\".strip()\n",
    "\n",
    "def _reformat_action_data(action: Action):\n",
    "    if getattr(action, '_direction', '') == \"backtrack\":\n",
    "        return _process_backtrack_action(action)\n",
    "\n",
    "    if 'prev_V' not in action.metadata:\n",
    "        # first action\n",
    "        return action\n",
    "\n",
    "    action_clone = copy.deepcopy(action)\n",
    "    additional_reasoning = _find_best_judge(\n",
    "        action.metadata[\"prev_V\"],  # if you are going forward, at least b\n",
    "        action.metadata[\"prev_V_debate_data\"]['final_decisions']\n",
    "    )\n",
    "    assert additional_reasoning != \"\", f\"additional_reasoning is empty\"\n",
    "\n",
    "    forward_new_prediction = FORWARD_PROMPT.format(\n",
    "        judge_reasoning=additional_reasoning,\n",
    "        raw_action_prediction=action.raw_prediction\n",
    "    )\n",
    "    rephrased = _rephrase_success_estimate(forward_new_prediction, mode='forward')\n",
    "\n",
    "    action_clone.raw_prediction = rephrased\n",
    "    return action_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPHRASE_BACKTRACK_PRMOPT_W_STATE = \"\"\"\n",
    "Below are some texts that are generated using model-model interaction in the format of:\n",
    "```\n",
    "OBJECTIVE: <user intent>\n",
    "OBSERVATION: <observation>\n",
    "ACTION:\n",
    "Let's see what we have got. <Success estimate of current progress>\n",
    "\n",
    "<action reasoning>\n",
    "```\n",
    "where the success estimate is generated by a separate model.\n",
    "\n",
    "Your task is to:\n",
    "1. rephrase the text to make it look like its generated by a single model, WITHOUT using the word \"the agent\".\n",
    "2. The <success estimate> should be COHERENT with the current <action reasoning>. If there are conflicts, you can MODIFY the <success estimate> to make it coherent.\n",
    "3. If the <success estimate> seems ambiguous given the current <observation>, assume that its correct and simply PARAPHRASE it to make it COHERENT.\n",
    "4. make sure you keep the keywords such as \"Let's see what we have got\" and \"In summary\" intact.\n",
    "5. do NOT generate aything after rephrasing 2.\n",
    "\n",
    "For example:\n",
    "OBJECTIVE 1: Find the mileage of the red car in the second row.\n",
    "OBSERVATION 1: (omitted for brevity)\n",
    "## ACTION 1:\n",
    "Let's see what we have got. The agent's actions did not fulfill the user's intent of finding the mileage of the red car in the second row, which is the 1987 Porsche 911 Carrera. Instead, the agent navigated to the page of a different car, the 2010 Lincoln MKT, making the current state irrelevant to the user's request.\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```go_back```.\n",
    "## Rephrasing ACTION 1 as a standalone, coherent thought:\n",
    "Let's see what we have got. The current observation doesn't seem useful at fulfilling the user's intent of finding the mileage of the red car in the second row, which is the 1987 Porsche 911 Carrera. Instead, the agent navigated to the page of a different car, the 2010 Lincoln MKT, making the current state irrelevant to the user's request.\n",
    "\n",
    "We should take a step back and explore some other options.\n",
    "\n",
    "In summary, the next action I will perform is ```go_back```.\n",
    "\n",
    "OBJECTIVE 2: {objective}\n",
    "OBSERVATION 2: {observation}\n",
    "## ACTION 2:\n",
    "{original_text}\n",
    "## Rephrasing ACTION 2 as a standalone, coherent thought:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "REPHRASE_FORWARD_PRMOPT_W_STATE = \"\"\"\n",
    "Below are some texts that are generated using model-model interaction in the format of:\n",
    "```\n",
    "OBJECTIVE: <user intent>\n",
    "OBSERVATION: <observation>\n",
    "Let's see what we have got. <Success estimate of current progress>\n",
    "\n",
    "<action reasoning>\n",
    "```\n",
    "where the success estimate is generated by a separate model.\n",
    "\n",
    "Your task is to:\n",
    "1. rephrase the text to make it look like its generated by a single model, WITHOUT using the word \"the agent\".\n",
    "2. The <success estimate> should be COHERENT with the current <action reasoning>. If there are conflicts, you can MODIFY the <success estimate> to make it coherent.\n",
    "3. If the <success estimate> seems ambiguous given the current <observation>, assume that its correct and simply PARAPHRASE it to make it COHERENT.\n",
    "4. make sure you keep the keywords such as \"Let's see what we have got\" and \"In summary\" intact.\n",
    "5. do NOT generate aything after rephrasing 2.\n",
    "\n",
    "For example:\n",
    "OBJECTIVE 1: Find me a pillow with an animal pattern.\n",
    "OBSERVATION 1: (omitted for brevity)\n",
    "## Original 1:\n",
    "Let's see what we have got. I have navigated to the listings page for West Virginia, which is necessary to find the most expensive green vehicle. However, I have not yet filtered the listings by \"Cars + trucks\" and identified the green vehicle with the highest price, nor provided the lister's name. Therefore, the task is not complete and needs further actions.\n",
    "\n",
    "Let's think step-by-step.\n",
    "\n",
    "1. The listings have been filtered to those in West Virginia.\n",
    "2. Searching for green vehicles is the next step. The current listings show various items, including some vehicles.\n",
    "3. The task is to find the most expensive green vehicle. Among the listings, the \"1988-1998 Chevy 1500, 2500 6ft\" appears to be a green vehicle priced at $1200.\n",
    "\n",
    "Next, I will check the listing for this vehicle to confirm its color and find the lister's name. In summary, the next action I will perform is ```click [1028]```\n",
    "## Rephrasing 1 as a standalone, coherent thought:\n",
    "Let's see what we have got. I have navigated to the listings page for West Virginia, which is necessary to find the most expensive green vehicle. However, I have not yet identified the green vehicle with the highest price on this page. Therefore, the task is not complete and needs further actions.\n",
    "\n",
    "I think I should proceed with the following steps:\n",
    "\n",
    "1. The listings have been filtered to those in West Virginia.\n",
    "2. Searching for green vehicles is the next step. The current listings show various items, including some vehicles.\n",
    "3. The task is to find the most expensive green vehicle. Among the listings, the \"1988-1998 Chevy 1500, 2500 6ft\" appears to be a green vehicle priced at $1200.\n",
    "\n",
    "Next, I will check the listing for this vehicle to confirm its color and find the lister's name. In summary, the next action I will perform is ```click [1028]```\n",
    "\n",
    "OBJECTIVE 2: {objective}\n",
    "OBSERVATION 2: {observation}\n",
    "## ACTION 2:\n",
    "{original_text}\n",
    "\n",
    "Note that making the <success estimate> COHERENT with the current <action reasoning> is the MOST important. If needed, you can MODIFY the <success estimate> to make it coherent.\n",
    "## Rephrasing ACTION 2  as a standalone, coherent thought:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def _rephrase_success_estimate_v2(intent, state, prediction_str: str, mode='backtrack'):\n",
    "    try:\n",
    "        original_exec = re.search(r\"```(.+)```\", prediction_str).group(1)\n",
    "        \n",
    "        if mode == 'backtrack':\n",
    "            content = REPHRASE_BACKTRACK_PRMOPT_W_STATE.format(\n",
    "                objective=intent,\n",
    "                observation=state,\n",
    "                original_text=prediction_str.strip()\n",
    "            )\n",
    "        elif mode == 'forward':\n",
    "            content = REPHRASE_FORWARD_PRMOPT_W_STATE.format(\n",
    "                objective=intent,\n",
    "                observation=state,\n",
    "                original_text=prediction_str.strip()\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(f\"Unknown mode: {mode}\")\n",
    "        \n",
    "        completion = create_chat_completion_wrapper(\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "            top_p=0.95,\n",
    "            num_outputs=1,\n",
    "        )\n",
    "        rephrased_exec = re.search(r\"```(.+)```\", completion).group(1)\n",
    "        assert original_exec == rephrased_exec, f\"Original: {original_exec}, Rephrased: {rephrased_exec}\"\n",
    "\n",
    "        completion = completion.replace(\"## Rephrasing 2 as a standalone thought:\", \"\").strip()\n",
    "        print(f\"rephrased from {prediction_str}\\nto\\n{completion}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        completion = prediction_str\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TO_ALPHABET = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "    9: 'J',\n",
    "    10: 'K',\n",
    "}\n",
    "ALPHABET_TO_IDX = {v: k for k, v in IDX_TO_ALPHABET.items()}\n",
    "\n",
    "\n",
    "def __format_mcq_choices(choices):\n",
    "    formatted_choices = []\n",
    "    for idx, choice in enumerate(choices):\n",
    "        formatted_choices.append(f\"{IDX_TO_ALPHABET[idx]}: {choice}\")\n",
    "    return '\\n'.join(formatted_choices)\n",
    "\n",
    "\n",
    "CHOOSE_JUDGE_PROMPT = \"\"\"\n",
    "Below is a user intent, a text representation of a webpage, and an agent's action execution. The goal of the agent is to fulfill the user intent by executing the correct action.\n",
    "To evaluate the current progress and future success (i.e., potential) of curernt action, we have several judgements from different agents.\n",
    "````\n",
    "OBJECTIVE: <user intent>\n",
    "OBSERVATION: <text representation of a webpage>\n",
    "ACTION: <agent's action execution>\n",
    "\n",
    "JUDGES:\n",
    "<list of judgements>\n",
    "````\n",
    "\n",
    "Your task is to select the judgement from the list above that is the most coherent with both the OBSERVATION and the ACTION.\n",
    "\n",
    "OBJECTIVE: {intent}\n",
    "OBSERVATION: {observation}\n",
    "ACTION: {action}\n",
    "\n",
    "JUDGES:\n",
    "{mcq_choices}\n",
    "\n",
    "Select the judge reasoning that is the most coherent with both the OBSERVATION and the ACTION. Answer in the format of:\n",
    "OPTION: <one of A, B, C, etc.>\n",
    "REASON: <reasons for this choice>\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def __recover_task_intent(task_info):\n",
    "    intent  = task_info[\"intent\"]\n",
    "    images = task_info.get(\"images\", [])\n",
    "    # Caption the input image, if provided.\n",
    "    if images is not None and len(images) > 0:\n",
    "        image_input_caption = \"\"\n",
    "        for image_i, image in enumerate(images):\n",
    "            if image_i == 0:\n",
    "                image_input_caption += f'Input image {image_i+1}: \"{cached_caption_image_fn([image])[0]}\"'\n",
    "            else:\n",
    "                image_input_caption += f'input image {image_i+1}: \"{cached_caption_image_fn([image])[0]}\"'\n",
    "            if len(images) > 1:\n",
    "                image_input_caption += \", \"\n",
    "        # Update intent to include captions of input images.\n",
    "        intent = f\"{image_input_caption}\\nIntent: {intent}\"\n",
    "    return intent\n",
    "\n",
    "\n",
    "def _mcq_select_best_judge(intent_w_image, state_str, action_str, all_judge_reasons):\n",
    "    intent = intent_w_image\n",
    "    try:\n",
    "        mcq_choices = __format_mcq_choices(all_judge_reasons)\n",
    "        content = CHOOSE_JUDGE_PROMPT.format(\n",
    "            intent=intent,\n",
    "            observation=state_str,\n",
    "            action=action_str,\n",
    "            mcq_choices=mcq_choices\n",
    "        )\n",
    "        \n",
    "        completion = create_chat_completion_wrapper(\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }],\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=128,\n",
    "            top_p=0.95,\n",
    "            num_outputs=1,\n",
    "        )\n",
    "        extracted_option = re.search(r\"OPTION: (.+)\", completion).group(1).strip().capitalize()\n",
    "        judge_idx = ALPHABET_TO_IDX[extracted_option]\n",
    "        return all_judge_reasons[judge_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        completion = ''\n",
    "    return completion\n",
    "\n",
    "\n",
    "def _find_best_judge_v2(intent_w_image, state, action_reason, judge_reasonings):\n",
    "    extracted_reasonings = []\n",
    "    for reason in judge_reasonings:\n",
    "        if re.search(r\"Thoughts: (.+)\", reason) is None:\n",
    "            continue\n",
    "        thought = re.search(r\"Thoughts: (.+)\", reason).group(1)\n",
    "        extracted_reasonings.append(thought)\n",
    "    \n",
    "    selected_v = _mcq_select_best_judge(intent_w_image, state, action_reason, extracted_reasonings)\n",
    "    return selected_v\n",
    "\n",
    "\n",
    "def _process_backtrack_action_v2(intent_w_image, prev_state_text: str, action: Action):\n",
    "    action_clone = copy.deepcopy(action)\n",
    "    # first get judge\n",
    "    judges = action.metadata[\"prev_V_debate_data\"]['final_decisions']\n",
    "    assert len(judges) > 0, f\"judges is empty\"\n",
    "    additional_reasoning = _find_best_judge_v2(\n",
    "        intent_w_image,\n",
    "        prev_state_text,\n",
    "        action.raw_prediction,\n",
    "        judges\n",
    "    )\n",
    "    assert additional_reasoning != \"\", f\"additional_reasoning is empty\"\n",
    "    \n",
    "    # reformat current action\n",
    "    action_clone.element_id = ''\n",
    "    if action_clone.action_type == ActionTypes.SCROLL:\n",
    "        if '```scroll [up]```' in action_clone.raw_prediction:\n",
    "            backtrack_raw_prediction = BAKCTRACK_SCROLL_DOWN.format(judge_reasoning=additional_reasoning)\n",
    "        elif '```scroll [down]```' in action_clone.raw_prediction:\n",
    "            backtrack_raw_prediction = BAKCTRACK_SCROLL_UP.format(judge_reasoning=additional_reasoning)\n",
    "    elif action_clone.action_type == ActionTypes.GOTO_URL:\n",
    "        # our manual setting\n",
    "        real_url = action_clone._backtrack_url\n",
    "        backtrack_raw_prediction = BAKCTRACK_GOTO_URL.format(judge_reasoning=additional_reasoning, real_url=real_url)\n",
    "    else:\n",
    "        backtrack_raw_prediction = BAKCTRACK_BACK.format(judge_reasoning=additional_reasoning)\n",
    "        action_clone.action_type = ActionTypes.GO_BACK\n",
    "    \n",
    "    rephrased = _rephrase_success_estimate_v2(\n",
    "        intent_w_image,\n",
    "        prev_state_text,\n",
    "        backtrack_raw_prediction,\n",
    "        mode='backtrack'\n",
    "    )\n",
    "    action_clone.raw_prediction = rephrased\n",
    "    return action_clone\n",
    "\n",
    "\n",
    "def _reformat_action_data_v2(prev_state_text: str, action: Action, task_config: dict):\n",
    "    intent = __recover_task_intent({\n",
    "        \"intent\": task_config['intent'],\n",
    "        'images': task_config.get('images', [])\n",
    "    })\n",
    "\n",
    "    if getattr(action, '_direction', '') == \"backtrack\":\n",
    "        return _process_backtrack_action_v2(intent, prev_state_text, action)\n",
    "\n",
    "    if 'prev_V' not in action.metadata:\n",
    "        # first action\n",
    "        return action\n",
    "\n",
    "    action_clone = copy.deepcopy(action)\n",
    "    judges = action.metadata[\"prev_V_debate_data\"]['final_decisions']\n",
    "    additional_reasoning = _find_best_judge_v2(\n",
    "        intent,\n",
    "        prev_state_text,\n",
    "        action.raw_prediction,\n",
    "        judges\n",
    "    )\n",
    "    assert additional_reasoning != \"\", f\"additional_reasoning is empty\"\n",
    "\n",
    "    forward_new_prediction = FORWARD_PROMPT.format(\n",
    "        judge_reasoning=additional_reasoning,\n",
    "        raw_action_prediction=action.raw_prediction\n",
    "    )\n",
    "    rephrased = _rephrase_success_estimate_v2(\n",
    "        intent,\n",
    "        prev_state_text,\n",
    "        forward_new_prediction,\n",
    "        mode='forward'\n",
    "    )\n",
    "\n",
    "    action_clone.raw_prediction = rephrased\n",
    "    return action_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dtype(data):\n",
    "    if isinstance(data, dict):\n",
    "        prev_last_dtype = \"state\"\n",
    "    elif isinstance(data, Node):\n",
    "        prev_last_dtype = \"state\"\n",
    "    elif isinstance(data, Action):\n",
    "        prev_last_dtype = \"action\"\n",
    "    else:\n",
    "        raise Exception(f\"Unknown data type {type(data)}\")\n",
    "    return prev_last_dtype\n",
    "\n",
    "\n",
    "def merge_single_traversals(single_consecutive_traversal, task_config=None, dry_run=False):\n",
    "    ### step 1. concate all trajectories\n",
    "    all_concat_data = single_consecutive_traversal[0]\n",
    "    for partial_traj in single_consecutive_traversal[1:]:\n",
    "        prev_last_data = all_concat_data[-1]\n",
    "        prev_last_dtype = _get_dtype(prev_last_data)\n",
    "        \n",
    "        curr_first_dtype = _get_dtype(partial_traj[0])\n",
    "        if curr_first_dtype != \"state\":\n",
    "            raise Exception(f\"First data type is not state: {curr_first_dtype}\")\n",
    "        \n",
    "        # easy if we ended with an action\n",
    "        if prev_last_dtype == \"action\":\n",
    "            # get in!\n",
    "            all_concat_data.extend(partial_traj)\n",
    "        else:\n",
    "            # remove prev state\n",
    "            all_concat_data = all_concat_data[:-1]\n",
    "            all_concat_data.extend(partial_traj)\n",
    "\n",
    "    last_data_dtype = _get_dtype(all_concat_data[-1])\n",
    "    if last_data_dtype == \"state\":\n",
    "        # remove the last state\n",
    "        all_concat_data = all_concat_data[:-1]\n",
    "\n",
    "    ### step 1.5 add additional metadata\n",
    "    prev_action = None\n",
    "    for data in all_concat_data:\n",
    "        if isinstance(data, Action):\n",
    "            if prev_action is not None:\n",
    "                curr_v_debate = prev_action.metadata[\"next_V_debate_data\"]\n",
    "                curr_v = prev_action.metadata[\"V_next\"]\n",
    "                data.metadata[\"prev_V_debate_data\"] = curr_v_debate\n",
    "                data.metadata[\"prev_V\"] = curr_v\n",
    "            prev_action = data\n",
    "\n",
    "    ### step 2. convert all backtrack actions\n",
    "    backtracked_data = []\n",
    "    for idx, data in enumerate(all_concat_data):\n",
    "        if isinstance(data, tuple):\n",
    "            data, _ = data\n",
    "        if isinstance(data, Action):\n",
    "            if idx == 0:\n",
    "                prev_data = None\n",
    "            else:\n",
    "                prev_data = all_concat_data[idx-1]\n",
    "            \n",
    "            if not dry_run:\n",
    "                # data = _reformat_action_data(prev_data, data, task_config)\n",
    "                # prev data should be dict\n",
    "                prev_state_str = prev_data['observation']['text']\n",
    "                data = _reformat_action_data_v2(prev_state_str, data, task_config)\n",
    "        elif isinstance(data, Node):\n",
    "            try:\n",
    "                data = data.trajectory[-1]\n",
    "            except:\n",
    "                print('encountering terminal state before last action')\n",
    "                print('error')\n",
    "                break\n",
    "        backtracked_data.append(data)\n",
    "    return backtracked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check other stuff such as how often does it backtrack, and the lonegst consecutive backtracking\n",
    "\n",
    "def _traj_num_consecutive_backtrack(trajectory):\n",
    "    consec_nums = []\n",
    "    num_consecutive = 0\n",
    "    is_prev_backtrack = False\n",
    "    for data in trajectory:\n",
    "        if isinstance(data, Action):\n",
    "            direction = getattr(data, '_direction', '')\n",
    "            if direction == 'backtrack':\n",
    "                if is_prev_backtrack:\n",
    "                    num_consecutive += 1\n",
    "                else:\n",
    "                    num_consecutive = 1\n",
    "                is_prev_backtrack = True\n",
    "            else:\n",
    "                is_prev_backtrack = False\n",
    "                consec_nums.append(num_consecutive)\n",
    "                num_consecutive = 0\n",
    "    consec_nums.append(num_consecutive)\n",
    "    return max(consec_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config_base = DSET_NAME_TO_FOLDER[dset_name]\n",
    "\n",
    "num_passed = 0\n",
    "num_failed = 0\n",
    "num_skipped = 0\n",
    "total_length = {}\n",
    "all_formatted_traj = []\n",
    "all_formatted_tids = []\n",
    "pbar = tqdm(total=len(successful_data[:]))\n",
    "#### testing code, not real run (dry_run=True)\n",
    "for i in range(len(successful_data[:])):\n",
    "    print('processing', i)\n",
    "    try:\n",
    "        tid = successful_data[i]['task_id']\n",
    "        config_file_path = f\"{task_config_base}/{tid}.json\"\n",
    "        with open(config_file_path, 'r') as f:\n",
    "            task_config = json.load(f)\n",
    "\n",
    "        all_traversals = process_single_traj(successful_data[i][\"traj\"], successful_data[i][\"trees\"])\n",
    "        single_traversal = merge_single_traversals(all_traversals, task_config, dry_run=False)  # use dry_run=True to check errors first\n",
    "        n_backtrack = _traj_num_consecutive_backtrack(single_traversal)\n",
    "        print(f\"idx={i}, {n_backtrack=}\")\n",
    "        if len(single_traversal) > 35:\n",
    "            print('length > 35, skipping')\n",
    "            num_skipped += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        num_passed += 1\n",
    "        curr_len = len(single_traversal)\n",
    "        if curr_len not in total_length:\n",
    "            total_length[curr_len] = 0\n",
    "        total_length[curr_len] += 1\n",
    "\n",
    "        all_formatted_traj.append(single_traversal)\n",
    "        all_formatted_tids.append(tid)\n",
    "    except Exception as e:\n",
    "        print('processing error at', i)\n",
    "        print(traceback.format_exc())\n",
    "        print('============')\n",
    "        num_failed += 1\n",
    "    pbar.update(1)\n",
    "save_llm_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('collected', len(all_formatted_traj))\n",
    "for k, v in total_length.items():\n",
    "    if k < 25:\n",
    "        print(f\"length={k}, {v=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifieds\n",
    "assert dset_name == \"classifieds\"\n",
    "tree_traj_save_path = f\"tmp_{dset_name}_tree.pkl.xz\"\n",
    "\n",
    "truncated_formatted_trajs = []\n",
    "for traj in all_formatted_traj:\n",
    "    truncated_traj = traj[:100] # no truncation\n",
    "    truncated_formatted_trajs.append(truncated_traj)\n",
    "\n",
    "with lzma.open(tree_traj_save_path, \"wb\") as fwrite:\n",
    "    pickle.dump(truncated_formatted_trajs, fwrite)\n",
    "\n",
    "# also save the tisd\n",
    "tree_tid_save_path = f\"tmp_{dset_name}_tree_tids.txt\"\n",
    "all_tids_str = \",\".join([str(x) for x in all_formatted_tids])\n",
    "with open(tree_tid_save_path, \"w\") as fwrite:\n",
    "    fwrite.write(all_tids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### reddit\n",
    "# assert dset_name == \"reddit\"\n",
    "# tree_traj_save_path = f\"tmp_{dset_name}_tree.pkl.xz\"\n",
    "\n",
    "# truncated_formatted_trajs = []\n",
    "# for traj in all_formatted_traj:\n",
    "#     truncated_traj = traj[:100] # no truncation\n",
    "#     truncated_formatted_trajs.append(truncated_traj)\n",
    "\n",
    "# with lzma.open(tree_traj_save_path, \"wb\") as fwrite:\n",
    "#     pickle.dump(truncated_formatted_trajs, fwrite)\n",
    "\n",
    "# # also save the tisd\n",
    "# tree_tid_save_path = f\"tmp_{dset_name}_tree_tids.txt\"\n",
    "# all_tids_str = \",\".join([str(x) for x in all_formatted_tids])\n",
    "# with open(tree_tid_save_path, \"w\") as fwrite:\n",
    "#     fwrite.write(all_tids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### shopping\n",
    "# assert dset_name == \"shopping\"\n",
    "# tree_traj_save_path = f\"tmp_{dset_name}_tree.pkl.xz\"\n",
    "\n",
    "# truncated_formatted_trajs = []\n",
    "# for traj in all_formatted_traj:\n",
    "#     truncated_traj = traj[:100] # no truncation\n",
    "#     truncated_formatted_trajs.append(truncated_traj)\n",
    "\n",
    "# with lzma.open(tree_traj_save_path, \"wb\") as fwrite:\n",
    "#     pickle.dump(truncated_formatted_trajs, fwrite)\n",
    "\n",
    "# # also save the tisd\n",
    "# tree_tid_save_path = f\"tmp_{dset_name}_tree_tids.txt\"\n",
    "# all_tids_str = \",\".join([str(x) for x in all_formatted_tids])\n",
    "# with open(tree_tid_save_path, \"w\") as fwrite:\n",
    "#     fwrite.write(all_tids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(truncated_formatted_trajs), len(all_formatted_tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_task_config(dset_name, tid):\n",
    "    eval_config_file = f\"{DSET_NAME_TO_FOLDER[dset_name]}/{tid}.json\"\n",
    "    if not os.path.exists(eval_config_file):\n",
    "        raise Exception(f\"Cannot find {eval_config_file}\")\n",
    "    \n",
    "    with open(eval_config_file, \"r\") as fread:\n",
    "        eval_config = json.load(fread)\n",
    "    return eval_config\n",
    "\n",
    "\n",
    "def traj_to_html(task_config_dict, single_trajectory):\n",
    "    task_id = task_config_dict['task_id']\n",
    "    intent = task_config_dict['intent']\n",
    "    intent_images = task_config_dict.get('images', [])\n",
    "\n",
    "    obs_counter = 0\n",
    "    action_counter = 0\n",
    "    title_div = f\"\"\"\n",
    "    <div>\n",
    "        <h3 id=\"task\" class=\"no-skip\"><pre>\n",
    "        Task ID: {task_id}\n",
    "        Intent: {intent}\n",
    "        Intent_image: {intent_images}\n",
    "        </pre></h3>\n",
    "    </div>\n",
    "    \"\"\".replace(\" \"*4, \"\").strip()\n",
    "\n",
    "    content_hist = [title_div]\n",
    "    for data in single_trajectory:\n",
    "        if isinstance(data, dict):\n",
    "            image_array = data['observation']['image']\n",
    "            image_pil = Image.fromarray(image_array).resize((640, 1024))\n",
    "            image_b64 = pil_to_b64(image_pil)\n",
    "            data_div = f\"\"\"\n",
    "            <div><pre id=\"observation {obs_counter}\" class=\"no-skip\">\n",
    "                OBSERVATION:\n",
    "                {data['observation']['text']}\n",
    "                IMAGE:\n",
    "                <img src=\"{image_b64}\"/>\n",
    "            </pre></div>\n",
    "            \"\"\".replace(\" \"*4, \"\").strip()\n",
    "            obs_counter += 1\n",
    "        elif isinstance(data, Action):\n",
    "            data_div = f\"\"\"\n",
    "            <div class=\"action\"><pre id=\"action {action_counter}\" class=\"no-skip\">\n",
    "                ACTION: {data.raw_prediction}\n",
    "            </pre></div>\n",
    "            \"\"\".replace(\" \"*4, \"\").strip()\n",
    "            action_counter += 1\n",
    "        else:\n",
    "            raise Exception(f\"Unknown data type {type(data)}\")\n",
    "        content_hist.append(data_div)\n",
    "    \n",
    "    content = \"\\n\".join(content_hist)\n",
    "    skip_style = \".skip {display: none;}\"\n",
    "    no_train_style = \".no-train {background-color: #0307f81f;}\"\n",
    "    action_style = \".action {background-color: #f0f0f0;}\"\n",
    "    pre_style = \"pre {white-space: pre-wrap; word-wrap: break-word;}\"\n",
    "    html_data = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            {skip_style}\n",
    "            {no_train_style}\n",
    "            {action_style}\n",
    "            {pre_style}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    {content}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\".replace(\" \"*4, \"\").strip()\n",
    "    return html_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ preview the data in html\n",
    "# since env is dynamic, sometimes the algorithm above cannot correctly identify ancestor states\n",
    "print(f\"Processing {dset_name}\")\n",
    "if not os.path.exists(f\"outputs/htmls/{dset_name}_text\"):\n",
    "    os.makedirs(f\"outputs/htmls/{dset_name}_text\")\n",
    "\n",
    "pbar = tqdm(total=len(truncated_formatted_trajs))\n",
    "for traj, tid in zip(truncated_formatted_trajs, all_formatted_tids):\n",
    "    config_file = _load_task_config(dset_name, tid)\n",
    "    html_data = traj_to_html(config_file, traj)\n",
    "    html_file = f'outputs/htmls/{dset_name}_text/task_{tid}.html'\n",
    "    with open(html_file, \"w\") as fwrite:\n",
    "        fwrite.write(html_data)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save\n",
    "from datetime import datetime\n",
    "str_date = datetime.now().strftime(\"%m%d\")\n",
    "\n",
    "tree_checked_traj_save_path = f\"tmp_{dset_name}_tree_checked_{str_date}.pkl.xz\"\n",
    "with lzma.open(tree_checked_traj_save_path, \"wb\") as fwrite:\n",
    "    pickle.dump(truncated_formatted_trajs, fwrite)\n",
    "\n",
    "# also save the tisd\n",
    "tree_checked_tid_save_path = f\"tmp_{dset_name}_tree_tids_checked_{str_date}.txt\"\n",
    "all_tids_str = \",\".join([str(x) for x in all_formatted_tids])\n",
    "with open(tree_checked_tid_save_path, \"w\") as fwrite:\n",
    "    fwrite.write(all_tids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTRACK_KWD = \"We should take a step back\"\n",
    "import random\n",
    "\n",
    "def _traj_has_backtrack(traj_list):\n",
    "    for data in traj_list:\n",
    "        if isinstance(data, Action):\n",
    "            if BACKTRACK_KWD in data.raw_prediction:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "# lets make max traj to 30\n",
    "NUM_TRAJ = 30\n",
    "num_has_backtrack = 0\n",
    "_has_backtrack_trajs = []\n",
    "_has_backtrack_tids = []\n",
    "_non_backtrack_trajs = []\n",
    "_non_backtrack_tids = []\n",
    "\n",
    "for traj, tid in zip(truncated_formatted_trajs, all_formatted_tids):\n",
    "    if _traj_has_backtrack(traj):\n",
    "        _has_backtrack_trajs.append(traj)\n",
    "        _has_backtrack_tids.append(tid)\n",
    "        num_has_backtrack += 1\n",
    "    else:\n",
    "        _non_backtrack_trajs.append(traj)\n",
    "        _non_backtrack_tids.append(tid)\n",
    "\n",
    "rng.shuffle(_non_backtrack_trajs)\n",
    "# truncate non backtrack such that total length is 30\n",
    "num_non_backtrack_to_keep = NUM_TRAJ - num_has_backtrack\n",
    "_non_backtrack_trajs = _non_backtrack_trajs[:num_non_backtrack_to_keep]\n",
    "_non_backtrack_tids = _non_backtrack_tids[:num_non_backtrack_to_keep]\n",
    "\n",
    "# combine\n",
    "rebalanced_filtered_trainable_tree_chats = _has_backtrack_trajs + _non_backtrack_trajs\n",
    "rebalanced_filtered_trainable_tids = _has_backtrack_tids + _non_backtrack_tids\n",
    "percent_has_backtrack = num_has_backtrack / len(rebalanced_filtered_trainable_tree_chats)\n",
    "print(f\"num has backtrack: {num_has_backtrack} out of {len(rebalanced_filtered_trainable_tree_chats)}, percentage {percent_has_backtrack*100.0:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_traj(traj: list):\n",
    "    # make sure last actoin id can be found\n",
    "    action_element_id = traj[-1].element_id\n",
    "    if action_element_id == '':\n",
    "        return False\n",
    "    element_matching_text = f\"[{action_element_id}]\"\n",
    "    observation = traj[-2]['observation']['text']\n",
    "    if element_matching_text not in observation:\n",
    "        return True  # remove\n",
    "\n",
    "    # check if the special field _remove_from_training is there\n",
    "    action = traj[-1]\n",
    "    if getattr(action, '_remove_from_training', False):\n",
    "        print('removing due to _remove_from_training')\n",
    "        return True\n",
    "    return False # keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(rebalanced_filtered_trainable_tree_chats) == len(rebalanced_filtered_trainable_tids)\n",
    "\n",
    "\n",
    "modality = \"text\"\n",
    "raw_trainable_tree_chats = []\n",
    "raw_kept_tids = []\n",
    "num_filtered = 0\n",
    "pbar = tqdm(total=len(rebalanced_filtered_trainable_tree_chats))\n",
    "for tid, traj in zip(rebalanced_filtered_trainable_tids, rebalanced_filtered_trainable_tree_chats):\n",
    "    ### get all separated trajectory\n",
    "    # (s,a), (s,a,s,a), ...\n",
    "    end_idx = 2\n",
    "    while end_idx < len(traj)+1:\n",
    "        partial_traj = copy.deepcopy(traj[:end_idx])\n",
    "        # truncation\n",
    "        if len(partial_traj) > 16:\n",
    "            # cut to max length of 16\n",
    "            print('truncating partial traj in', tid)\n",
    "            partial_traj = partial_traj[:4] + partial_traj[-12:]\n",
    "        if _filter_traj(partial_traj):\n",
    "            end_idx += 2\n",
    "            continue\n",
    "\n",
    "        trainable_chat = get_single_training_data_from_trajectory(partial_traj, tid, dset_name, tree_prompt_constructor, modality)\n",
    "        if _filter_train_data(trainable_chat['messages']):\n",
    "            num_filtered += 1\n",
    "        else:\n",
    "            # good\n",
    "            print('post processing', tid)\n",
    "            # no rephrase since during editing, this should be taken care of\n",
    "            trainable_chat = _trainable_chat_postprocessing(trainable_chat, no_rephrase=True)\n",
    "            raw_trainable_tree_chats.append(trainable_chat)\n",
    "            raw_kept_tids.append(tid)\n",
    "        end_idx += 2\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_llm_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('in total length', len(set(raw_kept_tids)))\n",
    "print(set(raw_kept_tids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 10 samples\n",
    "rng = random.Random(42)\n",
    "ran_10_samples = rng.sample(raw_trainable_tree_chats, 5)\n",
    "\n",
    "for idx, data_sample in enumerate(ran_10_samples):\n",
    "    print(f\"sample {idx}\")\n",
    "    display_trainable_chat(data_sample)\n",
    "    print(\"\\n\\n\\n\\n=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "import jsonlines\n",
    "from datetime import datetime\n",
    "\n",
    "str_date = datetime.now().strftime(\"%m%d\")\n",
    "final_tree_train_path = f\"outputs/final/{dset_name}_puretext_tree_{str_date}.jsonl\"\n",
    "with jsonlines.open(final_tree_train_path, \"w\") as fwrite:\n",
    "    fwrite.write_all(raw_trainable_tree_chats)\n",
    "print(f\"saved {len(raw_trainable_tree_chats)} chats to {final_tree_train_path}\")\n",
    "\n",
    "final_tree_train_tid_path = f\"outputs/final/{dset_name}_puretext_tree_{str_date}_tids.txt\"\n",
    "with open(final_tree_train_tid_path, \"w\") as fwrite:\n",
    "    fwrite.write(\",\".join([str(x) for x in raw_kept_tids]))\n",
    "print(f\"saved {len(raw_kept_tids)} tids to {final_tree_train_tid_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_format_errors(raw_trainable_tree_chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Non-Tree data from tree data\n",
    "\n",
    "just use the tids\n",
    "note that you also need to change prompt constructor now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_value_before_action(action):\n",
    "    prediction_str = action.raw_prediction\n",
    "    if \"Let's see what we have got\" in prediction_str:\n",
    "        # remove the first sentence\n",
    "        sents = prediction_str.split(\"\\n\")\n",
    "        new_sents = sents[1:]\n",
    "        new_prediction_str = \"\\n\".join(new_sents)\n",
    "        action.raw_prediction = new_prediction_str\n",
    "    return action\n",
    "\n",
    "\n",
    "def _remove_backtrack_to_normal_action(traj):\n",
    "    new_traj = []\n",
    "    for data in traj:\n",
    "        if isinstance(data, Action):\n",
    "            copied_data = copy.deepcopy(data)\n",
    "            if getattr(copied_data, '_direction', '') == \"backtrack\":\n",
    "                # skip checking following, which is patched manually\n",
    "                backtrack_url = getattr(copied_data, '_backtrack_url', '')\n",
    "                if backtrack_url == 'http://onestopmarket.com/home-kitchen/heating-cooling-air-quality.html?product_list_order=price':\n",
    "                    directly_correct_action = _remove_value_before_action(copied_data)\n",
    "                    new_traj.append(directly_correct_action)\n",
    "                    continue\n",
    "                if backtrack_url == 'http://wikipedia.org/search?content=wikipedia_en_all_maxi_2022-05&pattern=Major+commercial+airport+in+Washington+state':\n",
    "                    copied_data._n_action_reversed = 1\n",
    "\n",
    "                n_action_reversed = copied_data._n_action_reversed\n",
    "                if n_action_reversed > 1:\n",
    "                    # assert n_action_reversed == 1, f\"n_action_reversed is not 1: {n_action_reversed}\"\n",
    "                    # pop all the way until the state has the same url as this one\n",
    "                    bactrack_url = copied_data._backtrack_url\n",
    "                    while True:\n",
    "                        prev_data = new_traj[-1]\n",
    "                        if isinstance(prev_data, dict):\n",
    "                            converted_url = map_url_to_real(prev_data['url'])\n",
    "                            if converted_url == bactrack_url:\n",
    "                                new_traj.pop()\n",
    "                                break\n",
    "                        new_traj.pop()\n",
    "                else:\n",
    "                    # was (a,s,a to bracktrack,s,backtrack,s,a), pop\n",
    "                    # skip this and pop s,a,s\n",
    "                    new_traj.pop()\n",
    "                    new_traj.pop()\n",
    "                    new_traj.pop()\n",
    "            else:\n",
    "                directly_correct_action = _remove_value_before_action(copied_data)\n",
    "                new_traj.append(directly_correct_action)\n",
    "        else:\n",
    "            new_traj.append(data)\n",
    "    return new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directly_correct_tids = []\n",
    "directly_correct_chats = []\n",
    "for tid, traj in zip(rebalanced_filtered_trainable_tids, rebalanced_filtered_trainable_tree_chats):\n",
    "    flattened_traj = _remove_backtrack_to_normal_action(traj)\n",
    "    directly_correct_tids.append(tid)\n",
    "    directly_correct_chats.append(flattened_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### text modality\n",
    "import argparse\n",
    "from src.agentic.policy import CoTPolicyPConstructor\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    instruction_path=\"../../src/prompts/vwa/jsons/p_cot_id_actree_3s_final_norefl_noicl.json\",\n",
    ")\n",
    "\n",
    "prompt_constructor = CoTPolicyPConstructor(\n",
    "    instruction_path=args.instruction_path,\n",
    "    lm_config=llm_config,\n",
    "    tokenizer=llm_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process to jsonl training data\n",
    "\n",
    "modality = \"text\"\n",
    "raw_trainable_flat_chats = []\n",
    "raw_kept_tids = []\n",
    "num_filtered = 0\n",
    "pbar = tqdm(total=len(directly_correct_chats))\n",
    "for tid, traj in zip(directly_correct_tids, directly_correct_chats):\n",
    "    ### get all separated trajectory\n",
    "    # (s,a), (s,a,s,a), ...|\n",
    "    end_idx = 2\n",
    "    while end_idx < len(traj)+1:\n",
    "        partial_traj = copy.deepcopy(traj[:end_idx])\n",
    "        # truncation\n",
    "        if len(partial_traj) > 16:\n",
    "            # cut to max length of 16\n",
    "            print('truncating partial traj in', tid)\n",
    "            partial_traj = partial_traj[:4] + partial_traj[-12:]\n",
    "        if _filter_traj(partial_traj):\n",
    "            end_idx += 2\n",
    "            continue\n",
    "\n",
    "        trainable_chat = get_single_training_data_from_trajectory(partial_traj, tid, dset_name, prompt_constructor, modality)\n",
    "        if _filter_train_data(trainable_chat['messages']):\n",
    "            num_filtered += 1\n",
    "        else:\n",
    "            # good\n",
    "            print('post processing', tid)\n",
    "            # no rephrase since during editing, this should be taken care of\n",
    "            trainable_chat = _trainable_chat_postprocessing(trainable_chat, no_rephrase=True)\n",
    "            raw_trainable_flat_chats.append(trainable_chat)\n",
    "            raw_kept_tids.append(tid)\n",
    "        end_idx += 2\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 10 samples\n",
    "rng = random.Random(42)\n",
    "ran_10_samples = rng.sample(raw_trainable_flat_chats, 5)\n",
    "\n",
    "for idx, data_sample in enumerate(ran_10_samples):\n",
    "    print(f\"sample {idx}\")\n",
    "    display_trainable_chat(data_sample)\n",
    "    print(\"\\n\\n\\n\\n=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "import jsonlines\n",
    "from datetime import datetime\n",
    "\n",
    "str_date = datetime.now().strftime(\"%m%d\")\n",
    "final_flat_train_path = f\"outputs/final/{dset_name}_puretext_flat_{str_date}.jsonl\"\n",
    "with jsonlines.open(final_flat_train_path, \"w\") as fwrite:\n",
    "    fwrite.write_all(raw_trainable_flat_chats)\n",
    "print(f\"saved {len(raw_trainable_flat_chats)} chats to {final_flat_train_path}\")\n",
    "\n",
    "final_flat_train_tid_path = f\"outputs/final/{dset_name}_puretext_flat_{str_date}_tids.txt\"\n",
    "with open(final_flat_train_tid_path, \"w\") as fwrite:\n",
    "    fwrite.write(\",\".join([str(x) for x in raw_kept_tids]))\n",
    "print(f\"saved {len(raw_kept_tids)} (unique = {len(set(raw_kept_tids))}) tids to {final_flat_train_tid_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all jsonl into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_root = \"outputs/final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(42)\n",
    "\n",
    "concat_final_tree = []\n",
    "for file in os.listdir(final_result_root):\n",
    "    if file.endswith(\".jsonl\") and \"tree\" in file:\n",
    "        print(f\"Processing {file}\")\n",
    "\n",
    "        fpath = os.path.join(final_result_root, file)\n",
    "        with jsonlines.open(fpath, \"r\") as fread:\n",
    "            data = list(fread)\n",
    "            concat_final_tree.extend(data)\n",
    "        \n",
    "print(f'got {len(concat_final_tree)} data')\n",
    "# shuffle\n",
    "rng.shuffle(concat_final_tree)\n",
    "print('shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_tree_save_path = f\"outputs/final/allenv_puretext_tree.jsonl\"\n",
    "with jsonlines.open(concate_tree_save_path, \"w\") as fwrite:\n",
    "    fwrite.write_all(concat_final_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "check_format_errors(concat_final_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(42)\n",
    "\n",
    "concat_final_flat = []\n",
    "for file in os.listdir(final_result_root):\n",
    "    if file.endswith(\".jsonl\") and \"flat\" in file:\n",
    "        print(f\"Processing {file}\")\n",
    "\n",
    "        fpath = os.path.join(final_result_root, file)\n",
    "        with jsonlines.open(fpath, \"r\") as fread:\n",
    "            data = list(fread)\n",
    "            concat_final_flat.extend(data)\n",
    "        \n",
    "print(f'got {len(concat_final_flat)} data')\n",
    "# shuffle\n",
    "rng.shuffle(concat_final_flat)\n",
    "print('shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_flat_save_path = f\"outputs/final/allenv_puretext_flat.jsonl\"\n",
    "with jsonlines.open(concate_flat_save_path, \"w\") as fwrite:\n",
    "    fwrite.write_all(concat_final_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_format_errors(concat_final_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
